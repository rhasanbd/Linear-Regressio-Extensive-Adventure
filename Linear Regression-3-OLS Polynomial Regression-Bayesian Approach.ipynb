{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial Regression - Bayesian Approach\n",
    "\n",
    "\n",
    "<font color=red size=3> **Application Scenario:**</font> \n",
    "The Bayesian Polynomial Regression or Regularized Polynomial Regression is suitable for the following scenario.\n",
    "- Relationship between input (features) and output (target): Nonlinear\n",
    "- The Polynomial Regression model is too complex and overfits the data (high variance)\n",
    "- We need a complex model but want to \"turn off\" the non-discriminative polynomial features. In other words, we want to regularize the complex model.\n",
    "\n",
    "\n",
    "\n",
    "## Choosing Model Complexity in High-Degree Polynomial Regression\n",
    "\n",
    "There are two approaches to making an optimal tradeoff between overfitting (high variance) and underfitting (high bias).\n",
    "- <font color=red>Frequentist Learning (MLE)</font>: \n",
    "   \n",
    "   -- Using cross-validation determine the optimal degree (model complexity) that produces the best generalization\n",
    "   \n",
    "   -- Using the learning curve to determine the optimal degree (model complexity) that produces the best generalization\n",
    "   \n",
    "- <font color=red>Bayesian Learning (MAP or regularized regression)</font>: \n",
    "   \n",
    "   -- Using cross-validation learn the optimal regularization (penalty) coefficients that produce the best generalization\n",
    "\n",
    "\n",
    "##### In this notebook we implement the Bayesian approach.\n",
    "We perform **regularized polynomial linear regression** using sklearn's **regularized OLS Linear Regression** model.\n",
    "\n",
    "\n",
    "### Dataset\n",
    "\n",
    "URL: https://lib.stat.cmu.edu/datasets/boston\n",
    "\n",
    "This dataset provides housing values in the suburbs of Boston.\n",
    "\n",
    "The **MEDV** variable is the target variable.\n",
    "\n",
    "### Data description\n",
    "\n",
    "The Boston data frame has 506 rows and 14 columns.\n",
    "\n",
    "This data frame contains the following columns:\n",
    "\n",
    "- CRIM: per capita crime rate by town.\n",
    "\n",
    "- ZN: proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "\n",
    "- INDUS: proportion of non-retail business acres per town.\n",
    "\n",
    "- CHAS: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).\n",
    "\n",
    "- NOX: nitrogen oxides concentration (parts per 10 million).\n",
    "\n",
    "- RM: average number of rooms per dwelling.\n",
    "\n",
    "- AGE: proportion of owner-occupied units built prior to 1940.\n",
    "\n",
    "- DIS: weighted mean of distances to five Boston employment centers.\n",
    "\n",
    "- RAD: index of accessibility to radial highways.\n",
    "\n",
    "- TAX: full-value property-tax rate per $10,000.\n",
    "\n",
    "- PTRATIO: pupil-teacher ratio by town.\n",
    "\n",
    "- B: 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town.\n",
    "\n",
    "- LSTAT: lower status of the population (percent).\n",
    "\n",
    "- MEDV: median value of owner-occupied homes in $1000s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zd/2ty0m0yn1jzc2zjgq1154kkxxmbbr2/T/ipykernel_99940/2278545472.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data as a Pandas DataFrame Object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size:  (506, 14)\n",
      "Feature Names:  ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# URL for the dataset\n",
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "\n",
    "# Read the dataset\n",
    "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "\n",
    "# Feature names \n",
    "feature_names = [\n",
    "    \"CRIM\", \"ZN\", \"INDUS\", \"CHAS\", \"NOX\", \"RM\", \"AGE\", \"DIS\", \"RAD\", \"TAX\",\n",
    "    \"PTRATIO\", \"B\", \"LSTAT\"\n",
    "]\n",
    "\n",
    "# Extract features and target\n",
    "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])  # Features\n",
    "target = raw_df.values[1::2, 2]  # Target\n",
    "\n",
    "# Create a DataFrame with feature names\n",
    "df = pd.DataFrame(data, columns=feature_names)\n",
    "\n",
    "# Add target column 'MEDV' to the DataFrame\n",
    "df['MEDV'] = target\n",
    "\n",
    "# Display the DataFrame shape, feature names, and target array shape\n",
    "print(\"Dataset size: \", df.shape)\n",
    "print(\"Feature Names: \", df.columns.tolist())\n",
    "\n",
    "\n",
    "#Display the top five rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description of the Data\n",
    "\n",
    "DataFrame’s info() method is useful to get a quick description of the data, in particular the total number of rows, and each attribute’s type and number of non-null values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   CRIM     506 non-null    float64\n",
      " 1   ZN       506 non-null    float64\n",
      " 2   INDUS    506 non-null    float64\n",
      " 3   CHAS     506 non-null    float64\n",
      " 4   NOX      506 non-null    float64\n",
      " 5   RM       506 non-null    float64\n",
      " 6   AGE      506 non-null    float64\n",
      " 7   DIS      506 non-null    float64\n",
      " 8   RAD      506 non-null    float64\n",
      " 9   TAX      506 non-null    float64\n",
      " 10  PTRATIO  506 non-null    float64\n",
      " 11  B        506 non-null    float64\n",
      " 12  LSTAT    506 non-null    float64\n",
      " 13  MEDV     506 non-null    float64\n",
      "dtypes: float64(14)\n",
      "memory usage: 55.5 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the Data: Describe Numerical Attributes\n",
    "\n",
    "DataFrame's describe() method shows a summary of the numerical attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.613524</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.653063</td>\n",
       "      <td>22.532806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.601545</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.141062</td>\n",
       "      <td>9.197104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>17.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.360000</td>\n",
       "      <td>21.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.677083</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
       "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.677083   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "              AGE         DIS         RAD         TAX     PTRATIO           B  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
       "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
       "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
       "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "            LSTAT        MEDV  \n",
       "count  506.000000  506.000000  \n",
       "mean    12.653063   22.532806  \n",
       "std      7.141062    9.197104  \n",
       "min      1.730000    5.000000  \n",
       "25%      6.950000   17.025000  \n",
       "50%     11.360000   21.200000  \n",
       "75%     16.955000   25.000000  \n",
       "max     37.970000   50.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Separate Feature Set (Data Matrix X) and Target (1D Array y)\n",
    "\n",
    "Create a data matrix (X) that contains all features and a 1D target array (y) containing the target.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (506, 13)\n",
      "y shape:  (506,)\n",
      "\n",
      "X data type:  float64\n",
      "y data type:  float64\n"
     ]
    }
   ],
   "source": [
    "# Make a deep copy of the data frame object. It contains all attributes (all features and the target)\n",
    "allData = df.copy()\n",
    "\n",
    "# Create separate data frame objects for X (features) and y (target)\n",
    "X = df.drop(columns='MEDV')  \n",
    "y = df['MEDV']\n",
    "\n",
    "\n",
    "# Convert the Pandas data frame objects X and y into numpy arrays.\n",
    "X = np.asarray(X) # Data Matrix containing all features excluding the target\n",
    "y = np.asarray(y) # 1D target array\n",
    "\n",
    "print(\"X shape: \", X.shape)\n",
    "print(\"y shape: \", y.shape)\n",
    "\n",
    "print(\"\\nX data type: \", X.dtype)\n",
    "print(\"y data type: \", y.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Train and Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Learning Approach for Bias-Variance Tradeoff (Choosing Model Complexity)\n",
    "\n",
    "\n",
    "Unlike the Frequentist approach (MLE) which is used to determine the optimal degree of the polynomial (how complex the model should be), the Bayesian approach enables us to determine the optimal regularization (penalty) coefficients that produce the best generalization.\n",
    "\n",
    "Recall that MLE picks the polynomial degree that is the best for modeling the training data. If the data is noisy (input and out have a nonlinear relationship), a high-degree polynomial is required that results in a complex function. Such complex models are prone to overfitting (has high variance).\n",
    "\n",
    "The Bayesian approach (Maximum a posteriori or MAP) is used to resolve this issue by encouraging the parameters to be small, thus resulting in a smoother curve. This is done by a technique called **regularization**. Regularization can “turn off” some features that don’t play any role in explaining the variation in our prediction. In the case of polynomial regression, it kills the non-discriminating polynomial features.\n",
    "\n",
    "Regularization allows complex models to be trained on datasets of limited size without severe overfitting, essentially by limiting the effective model complexity. We can afford a complex model without experiencing overfitting.\n",
    "\n",
    "\n",
    "\n",
    "### Regularized (Penalized) Regression\n",
    "\n",
    "\n",
    "In regularized Regression, we regularize (penalize) the model parameters that allow complex models (high-degree Polynomial Regression model) to be trained on datasets of limited size without severe overfitting. It essentially limits the effective model complexity. \n",
    "\n",
    "Thus, the problem of determining the optimal model complexity (degree of polynomial or the basis function) is shifted from one of finding the appropriate number of basis functions (that we did in the Frequentist approach) to one of determining a suitable value of the regularization coefficient.\n",
    "\n",
    "A model with some regularization typically performs better than a model without any regularization. Thus, we should generally prefer regularized Regression over plain Linear Regression.\n",
    "\n",
    "Moreover, the OLS method (Normal Equation) requires computing the inverse of a matrix, but that matrix is not always invertible. In contrast, the matrix for regularized Regression (e.g., Ridge Regression) is always invertible.\n",
    "\n",
    "To implement the Bayesian approach, we will train a high-degree polynomial model that might have high variance (suffers from overfitting). Then, we will reduce overfitting via regularization. First, we determine the optimal polynomial degree by using MLE and then reduce its overfitting.\n",
    "- Step 1: Using MLE determine the optimal degree of the high-degree polynomial.\n",
    "- Step 2: Then, apply the regularized OLS method (MAP) and determine the optimal value for the regularization parameter via hyperparameter tuning. We will see that due to regularization the model will be better generalizable by weakening some of the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Using MLE Determine the Optimal Degree of the Polynomial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0kAAAIjCAYAAADWYVDIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAACBOUlEQVR4nO3dd1xW5f/H8ffNVhHcgoJo7pF759YyM0dqZm6zZWpqmaNfpX5LUSvTlk21IWqaoywzd84c5R6puVIcWYILFDi/P04gt9wgIHDuG17Px+M8kHOuc87nPh2TD9d1fS6bYRiGAAAAAACSJDerAwAAAAAAZ0KSBAAAAACJkCQBAAAAQCIkSQAAAACQCEkSAAAAACRCkgQAAAAAiZAkAQAAAEAiJEkAAAAAkAhJEgAAAAAkQpIEAEjR4cOH9cADD8jf3182m02LFy+2OqQsdfz4cdlsNs2aNcvqUAAAWYQkCQAy0KxZs2Sz2RI2Dw8PFS9eXH379tXp06eTtG/WrJlsNpvKli3r8HorVqxIuNaCBQvsju3Zs0ddunRRSEiIfHx8VLx4cd1///1677337NqVLFnSLqbE24MPPnjHz9SnTx/t2bNH48eP11dffaXatWun4Ymk3pQpU2Sz2bRy5cpk23z66aey2Wz67rvvMiUGZ7N27Vq7/17e3t4qWrSomjVrpgkTJujChQtWhwgA2ZKH1QEAQHb0v//9T6VKlVJUVJS2bNmiWbNmacOGDdq7d698fHzs2vr4+OjIkSPaunWr6tata3ds9uzZ8vHxUVRUlN3+TZs2qXnz5ipRooSeeuopBQQE6NSpU9qyZYumTZumwYMH27WvXr26XnzxxSRxFitWLMXPcf36dW3evFn/93//p0GDBqXlEaRZt27d9NJLLyksLEytWrVy2CYsLEwFCxZUmzZtMjWWxEJCQnT9+nV5enpm2T1v9/zzz6tOnTqKjY3VhQsXtGnTJo0ZM0ZTpkzRN998oxYtWlgWGwBkRyRJAJAJ2rRpk9Dj8uSTT6pQoUKaNGmSvvvuO3Xt2tWubenSpRUTE6M5c+bYJUlRUVFatGiR2rZtq2+//dbunPHjx8vf31/btm1Tvnz57I6dP38+STzFixdXz5490/w54nsqbr/H3bh69ary5MmTZH+xYsXUvHlzLVy4UNOnT5e3t7fd8dOnT+uXX37R008/fVcJS1xcnG7cuJEkWU2OzWZLddvM0rhxY3Xp0sVu365du/TAAw+oc+fO2r9/vwIDA7M0pmvXril37txZek8AyCoMtwOALNC4cWNJ0tGjRx0ef/zxxzVv3jzFxcUl7Pv+++917dq1JElV/HUqV67sMHkpUqRIhsQ8duxYhYSESJJeeukl2Ww2lSxZMuH477//rjZt2sjPz0++vr5q2bKltmzZYneN+OGH69at03PPPaciRYooKCgo2Xv27NlTERER+uGHH5Icmzt3ruLi4tSjRw9J0ltvvaWGDRuqYMGCypUrl2rVqpVkSKJkJjmDBg3S7NmzVblyZXl7e2vZsmUqWbKkOnTokKR9VFSU/P399cwzz0hyPCepb9++8vX11enTp9WxY0f5+vqqcOHCGj58uGJjY+2ud/HiRfXq1Ut+fn7Kly+f+vTpo127dt31PKdq1app6tSpunTpkt5//327Y6dPn9YTTzyhokWLytvbW5UrV9aMGTOSXOPEiRNq37698uTJoyJFimjYsGFavny5bDab1q5dm9CuWbNmqlKlinbs2KEmTZood+7cevnllyVJ0dHRGjNmjMqUKSNvb28FBwdrxIgRio6OTnK/r7/+WrVq1VKuXLlUoEABdevWTadOnUr3MwCAzEJPEgBkgePHj0uS8ufP7/B49+7dNXbsWK1duzZh6FRYWJhatmzpMOkJCQnR5s2btXfvXlWpUuWO979586b+/vvvJPvz5MmjXLlyOTynU6dOypcvn4YNG6bHH39cDz30kHx9fSVJ+/btU+PGjeXn56cRI0bI09NTH3/8sZo1a6Z169apXr16dtd67rnnVLhwYb322mu6evVqsnF26tRJAwYMUFhYmDp16mR3LCwsTCEhIbrvvvskSdOmTVP79u3Vo0cP3bhxQ3PnztWjjz6qpUuXqm3btnbnrl69Wt98840GDRqkQoUKqVSpUurZs6cmT56sf/75RwUKFEho+/333ysyMvKOPW+xsbFq3bq16tWrp7feeksrV67U22+/rdKlS2vAgAGSzF6rdu3aaevWrRowYIAqVKigJUuWqE+fPileO7W6dOmi/v376+eff9b48eMlSefOnVP9+vUTksPChQtr2bJl6t+/vyIjIzV06FBJZo9eixYtFB4eriFDhiggIEBhYWFas2aNw3tdvHhRbdq0Ubdu3dSzZ08VLVpUcXFxat++vTZs2KCnn35aFStW1J49e/TOO+/ojz/+sCvyMX78eL366qvq2rWrnnzySV24cEHvvfeemjRpot9//z1DeysB4K4ZAIAMM3PmTEOSsXLlSuPChQvGqVOnjAULFhiFCxc2vL29jVOnTtm1b9q0qVG5cmXDMAyjdu3aRv/+/Q3DMIx///3X8PLyMr744gtjzZo1hiRj/vz5Cef9/PPPhru7u+Hu7m40aNDAGDFihLF8+XLjxo0bSWIKCQkxJDncQkNDU/w8x44dMyQZb775pt3+jh07Gl5eXsbRo0cT9p05c8bImzev0aRJkyTPo1GjRkZMTEyqnuGjjz5q+Pj4GBEREQn7Dh48aEgyRo8enbDv2rVrdufduHHDqFKlitGiRQu7/ZIMNzc3Y9++fXb7Dx06ZEgypk+fbre/ffv2RsmSJY24uDi7ZzBz5syENn369DEkGf/73//szq1Ro4ZRq1athO+//fZbQ5IxderUhH2xsbFGixYtklzTEUf/7W9XrVo1I3/+/Anf9+/f3wgMDDT+/vtvu3bdunUz/P39E57b22+/bUgyFi9enNDm+vXrRoUKFQxJxpo1axL2N23a1JBkfPTRR3bX/Oqrrww3Nzdj/fr1dvs/+ugjQ5KxceNGwzAM4/jx44a7u7sxfvx4u3Z79uwxPDw8kuwHAKsx3A4AMkGrVq1UuHBhBQcHq0uXLsqTJ4++++67FIeade/eXQsXLtSNGze0YMECubu765FHHnHY9v7779fmzZvVvn177dq1S5MnT1br1q1VvHhxh5Xf6tWrpxUrViTZHn/88TR/ttjYWP3888/q2LGj7rnnnoT9gYGB6t69uzZs2KDIyEi7c5566im5u7un6vo9e/ZUVFSUFi5cmLAvLCxMkhKG2kmy6wH7999/FRERocaNG+u3335Lcs2mTZuqUqVKdvvKlSunevXqafbs2Qn7/vnnHy1btkw9evSQzWa7Y6zPPvus3feNGzfWn3/+mfD9Tz/9JE9PTz311FMJ+9zc3DRw4MA7Xju1fH19dfnyZUmSYRj69ttv1a5dOxmGob///jtha926tSIiIhKez08//aTixYurffv2Cdfy8fGxizUxb29v9evXz27f/PnzVbFiRVWoUMHuXvG9ofG9UgsXLlRcXJy6du1q1y4gIEBly5ZNtvcKAKzCcDsAyAQffPCBypUrp4iICM2YMUO//PJLkkIEt+vWrZuGDx+uZcuWafbs2Xr44YeVN2/eZNvXqVMnIanatWuXFi1apHfeeUddunTRzp077ZKCQoUKJVsxLq0uXLiga9euqXz58kmOVaxYUXFxcTp16pQqV66csL9UqVKpvn6bNm1UoEABhYWFqW/fvpKkOXPmqFq1anbXXLp0qd544w3t3LnTbv6Lo+Qmufv37t1bgwYN0okTJxQSEqL58+fr5s2b6tWr1x3j9PHxUeHChe325c+fX//++2/C9ydOnFBgYGCSAgdlypS54/VT68qVKwnvyYULF3Tp0iV98skn+uSTTxy2jy/sceLECZUuXTrJ80outuLFi8vLy8tu3+HDh3XgwIEkz+H2ex0+fFiGYSRb6t7KyoEA4AhJEgBkgrp16yZUt+vYsaMaNWqk7t2769ChQwnzem4XGBioZs2a6e2339bGjRuTVLRLjpeXl+rUqaM6deqoXLly6tevn+bPn68xY8Zk2Oe5W8nNe3LE09NTXbt21aeffqpz587p5MmTOnz4sCZPnpzQZv369Wrfvr2aNGmiDz/8UIGBgfL09NTMmTMTep1Sc/9u3bpp2LBhmj17tl5++WV9/fXXql27tsME8Hap7RnLTDdv3tQff/yRMC8tvvBHz549k533VLVq1XTdy9EzjIuL07333qspU6Y4PCc4ODihnc1m07Jlyxw+t+T+TgCAVUiSACCTubu7KzQ0VM2bN9f777+vUaNGJdu2e/fuevLJJ5UvXz499NBDab5XfGIWHh6e7njvpHDhwsqdO7cOHTqU5NjBgwfl5uaW8MNxevXo0UMfffSR5s2bp2PHjslms9kNDfz222/l4+Oj5cuX2/XQzZw5M033KVCggNq2bavZs2erR48e2rhxo6ZOnXpXsScWEhKiNWvWJCmXfeTIkQy5/oIFC3T9+nW1bt1akvnfJm/evIqNjb1jz2FISIj2798vwzDsepPSElvp0qW1a9cutWzZMsXhiaVLl5ZhGCpVqpTKlSuX6usDgFWYkwQAWaBZs2aqW7eupk6dmmRh2MS6dOmiMWPG6MMPP0wytCmxNWvWyDCMJPt//PFHSUpVT0h6ubu764EHHtCSJUsSqvZJZlW1sLAwNWrUSH5+fnd1j/vuu08lS5bU119/rXnz5qlp06Z287nc3d1ls9nsym0fP37crppaavXq1Uv79+/XSy+9JHd3d3Xr1u2uYk+sdevWunnzpj799NOEfXFxcfrggw/u+tq7du3S0KFDlT9//oQ5Tu7u7urcubO+/fZb7d27N8k58etexcd2+vRpuzlsUVFRdrHeSdeuXXX69GmH51y/fj2hkmGnTp3k7u6ucePGJXlvDcPQxYsXU31PAMgK9CQBQBZ56aWX9Oijj2rWrFlJJvzH8/f319ixY+94rcGDB+vatWt65JFHVKFCBd24cUObNm3SvHnzVLJkySQT7E+fPq2vv/46yXV8fX3VsWPHNH+WN954QytWrFCjRo303HPPycPDQx9//LGio6PthsWll81mU/fu3TVhwgRJ0v/+9z+7423bttWUKVP04IMPqnv37jp//rw++OADlSlTRrt3707Tvdq2bauCBQtq/vz5atOmTYatMyWZQy3r1q2rF198UUeOHFGFChX03Xff6Z9//pHkeP6UI+vXr1dUVJRiY2N18eJFbdy4Ud999538/f21aNEiBQQEJLSdOHGi1qxZo3r16umpp55SpUqV9M8//+i3337TypUrE+79zDPP6P3339fjjz+uIUOGKDAwULNnz05YODc1sfXq1UvffPONnn32Wa1Zs0b33XefYmNjdfDgQX3zzTdavny5ateurdKlS+uNN97Q6NGjdfz4cXXs2FF58+bVsWPHtGjRIj399NMaPnx4Wh8vAGQe6wrrAUD2E1/yetu2bUmOxcbGGqVLlzZKly6dUA47cQnw5DgqA71s2TLjiSeeMCpUqGD4+voaXl5eRpkyZYzBgwcb586dszs/pRLgISEhKd47uRLghmEYv/32m9G6dWvD19fXyJ07t9G8eXNj06ZNqX4ed7Jv3z5DkuHt7W38+++/SY5//vnnRtmyZQ1vb2+jQoUKxsyZM40xY8YYt//TJskYOHBgivd67rnnDElGWFhYkmPJlQDPkydPkraO7n/hwgWje/fuRt68eQ1/f3+jb9++xsaNGw1Jxty5c1OMK/6/ffzm6elpFC5c2GjSpIkxfvx44/z58w7PO3funDFw4EAjODjY8PT0NAICAoyWLVsan3zyiV27P//802jbtq2RK1cuo3DhwsaLL76YULZ8y5YtCe1Sek9v3LhhTJo0yahcubLh7e1t5M+f36hVq5Yxbtw4uzLuhmGWRG/UqJGRJ08eI0+ePEaFChWMgQMHGocOHUrxOQBAVrMZhoPxGgAA5CDDhg3T559/rrNnzyapRJcZFi9erEceeUQbNmxIWBzXWUydOlXDhg3TX3/9peLFi1sdDgBYgiQJAJCjRUVFKTg4WA8//HCaCz+kxvXr1+0qw8XGxuqBBx7Q9u3bdfbs2TRV/svs2KKiolSjRg3Fxsbqjz/+sCwuALAac5IAADnS+fPntXLlSi1YsEAXL17UkCFDMuU+gwcP1vXr19WgQQNFR0dr4cKF2rRpkyZMmGBpgiSZBRVKlCih6tWrKyIiQl9//bUOHjxot8AuAOREJEkAgBxp//796tGjh4oUKaJ3331X1atXz5T7tGjRQm+//baWLl2qqKgolSlTRu+9954GDRqUKfdLi9atW+uzzz7T7NmzFRsbq0qVKmnu3Ll67LHHrA4NACzFcDsAAAAASIR1kgAAAAAgEZIkAAAAAEgk289JiouL05kzZ5Q3b95UL9oHAAAAIPsxDEOXL19WsWLF5OaWfH9Rtk+Szpw5o+DgYKvDAAAAAOAkTp06paCgoGSPZ/skKW/evJLMB+Hn52dxNAAAAACsEhkZqeDg4IQcITnZPkmKH2Ln5+dHkgQAAADgjtNwKNwAAAAAAImQJAEAAABAIiRJAAAAAJAISRIAAAAAJEKSBAAAAACJZPvqdgAAAFnl5s2bio2NtToMIMdwd3eXp6dnhl+XJAkAAOAuRUZG6u+//1Z0dLTVoQA5jre3twoVKpShy/2QJAEAANyFyMhInT59Wr6+vipUqJA8PT3vuAYLgLtnGIZu3rypiIgInT59WpIyLFEiSQIAALgLf//9t3x9fRUUFERyBGSxXLlyKW/evPrrr7/0999/Z1iSROEGAACAdLp586aio6Pl7+9PggRYxGazyd/fX9HR0bp582aGXJMkCQAAIJ3iizRkxsRxAKkX/3cwowqnkCQBAADcJXqRAGtl9N9BkiQAAAAASITCDQCA7C02Vlq/XgoPlwIDpcaNJXd3q6MCADgxkiQAQPa1cKE0ZIj011+39gUFSdOmSZ06WRcXAMCpMdwOAJA9LVwodelinyBJ0unT5v6FC62JC0CqzZo1SzabTbNmzbLbX7JkSZUsWfKur5ORxo4dK5vNprVr12baPZB1SJIAANlPbKzZg2QYSY/F7xs61GwHIF26d+8um82mOXPmpNguMjJSuXPnVr58+XT9+vUsii7jrV27VjabTWPHjrU6lFSJT9oSb7lz51aVKlX0f//3f4qMjHR4Xnxbb29vXbx40WGbf//9V7ly5Upoe7uLFy9q1KhRqly5snLnzq3cuXMrJCRELVu21Lhx43Tu3Dm79iVLlkwS6+3b8ePH7/qZpAXD7QAA2c/69Ul7kBIzDOnUKbNds2ZZFhaQbk44t65///6aM2eOZsyYoccffzzZdnPmzNH169fVp08f5cqVK0PuvWrVqgy5TkYaNGiQunXrphIlSlgdip3OnTurSpUqkqRz587pxx9/1IQJE7R06VJt3bpV3t7eSc7x8PDQjRs3NHv2bD3//PNJjs+ePVtRUVHy8PBQTEyM3bG//vpLDRs21KlTp1S9enX169dP+fLlU3h4uDZt2qSxY8fqvvvuU9GiRe3Oc3d31yuvvJLs58iXL186Pn36kSQBALKf8PCMbQdYyUnn1rVo0UKlSpXS6tWrdfLkyWSTgxkzZkgyk6qMUrp06Qy7VkYpVKiQChUqZHUYSXTp0kXdunVL+D4qKkr169fXrl27FBYWpn79+iU5p3Tp0jIMQzNnznSYJM2YMUPly5eXJB06dMju2JgxY3Tq1Cn973//06uvvprk3D179jhMeDw8PJyql47hdgCA7CcwMGPbAVZx4rl1NptN/fr1U1xcnGbOnOmwzb59+7R161ZVrVpVtWvXVkREhCZNmqSmTZuqWLFi8vLyUrFixdS7d28dPXo01fdObk7SP//8o2effVZFixZV7ty5VadOHS1atCjZ68yYMUMdOnRQyZIl5ePjowIFCqh169Zas2aNXbuxY8eqefPmkqRx48Y5HAaW0pyk77//Xs2bN5e/v79y5cqlatWqacqUKUl6YY4fPy6bzaa+ffvqyJEjeuSRR5Q/f37lyZNHrVq10q5du1L9jJLj4+OjHj16SJJ27NiRbLt+/fpp586d+u233+z279q1S7///rvD5EqSNm/eLEkaPHiww+P33nuvgoOD0xN6liJJAgBkP40bm79pT2lxQU9PqVSprIsJSCsXmFvXt29fubm5adasWTIcxBmfPMX3Ih04cECvvfaacuXKpUceeURDhw5V7dq1FRYWprp16+rEiRPpjuXatWtq1qyZPv74Y5UuXVpDhgxR+fLl9dhjj2nBggUOzxk4cKDOnTunVq1aadiwYXr44Ye1efNmtWrVSkuWLElo16xZM/Xp00eS1LRpU40ZMyZhu9MwsClTpqh9+/bavXu3unfvroEDB+r69et68cUX9eijjzp8bsePH1f9+vX1zz//6IknntD999+vVatWqXnz5knm89wND4/kB5X16dNH7u7uSRLgzz//XO7u7urdu7fD8woWLChJ+uOPPzIsTisw3A4AkP24u5tDkbp0SXosPnHy85Pq1TN/E9+wYdbGh5zh2jXp4MH0n799e+rm1n3+uVS7dvruUaGClDt3+s6VFBwcrAceeEA//fSTVq9erZYtWyYci4mJ0ddffy1vb2/17NlTklSxYkWFh4erQIECdtdZs2aNWrVqpTfeeEOffvppumKZPHmy9uzZo6eeekqffPJJwv5evXrpwQcfdHjO/v37Veq2X5aEh4erdu3aeumll9ShQwdJZpIkSV988YWaNWuW6mFhR48e1ciRI1WkSBFt3749oQdl/PjxatWqlRYvXqyvv/5avXr1sjtv3bp1mjhxokaOHJmw79VXX9Ubb7yhmTNnatSoUam6vyNRUVGaPXu2JKlRo0bJtgsMDFSbNm0UFhamt956S97e3oqOjtbs2bP10EMPKTCZnviuXbtqw4YNateunZ599lk1b95cNWvWlJ+fX4pxxcTEJPtcAwIC9Oyzz6buA2YUI5uLiIgwJBkRERFWhwIAyGqNGxuGu7thmD9OmltwsGF8+61hnD1rGI0aGYanp2F8/rnVkcJFXb9+3di/f79x/fr1pAd37LB/95xx27Hjrp/B/PnzDUlG9+7d7fYvWrTIkGR07do1Vde59957jZIlS9rtmzlzpiHJmDlzpt3+kJAQIyQkxG5fqVKlDC8vLyM8PDzJtVu2bOnwOskZPHiwIck4fvx4wr41a9YYkowxY8Y4PGfMmDGGJGPNmjUJ+/73v/8ZkoxJkyYlab9x40ZDktGiRYuEfceOHTMkGaVKlTJiY2Pt2scf69SpU6o+Q3w8nTt3NsaMGWOMGTPGGDBggFGiRAlDkvHII48kuYdhGIYko3z58oZhGMbChQsNScbcuXMNwzCMuXPnGpKMRYsWGYZhGOXLlzduTyfi4uKMl156yfDy8jIkGZIMm81mVKpUyRg5cqRx5syZJPcMCQlJaOtoq1at2h0/b4p/FxNJbW5ATxIAIHv6809p40Zp6lTp3nsdVwVbtUoaPFjq31/atUt6+20pheEnQJpUqCClMOfjjrZvl5555s7tPv747nqS7lKHDh1UuHBhLVq0SBEREfL395eUfMGGtWvXaurUqfr111/1999/283L8fLySlcMkZGROnbsmCpVqqSAgIAkxxs3buywIt6ff/6p0NBQrV69WqdPn1Z0dLTd8TNnzigkJCRdMUnS77//LulWT1RiDRo0kI+Pj3bu3JnkWPXq1eXmZj8rJigoSJJ06dKlNMXw7bff6ttvv7Xb9+ijj2revHkOy3cn9vDDD6tIkSKaMWOGHnvsMc2YMUNFihTRww8/nOw5NptNkydP1ogRI/Tjjz9qy5Yt2r59u3bs2KH9+/fr448/1k8//aR69erZneft7a2oqKg0fbbMxL8EAIDsafJkqVAh6cknpeTKDnt5SR99JFWrJj3/vLRvnzRvnvTfmHrgruTOLdWsmf7zq1WTXn/dLNLgaF6SzWbOvevf39Jy4J6enurVq5emTJmisLAwDRgwQGfPntWyZctUokQJtWrVKqHt/Pnz9dhjj8nX11etW7dWyZIllTt37oSFXtM7Jyl+zZ8iRYo4PH57uWlJOnLkiOrWravIyEg1b95c7dq1k5+fn9zc3LR27VqtW7cuSdKU3rgc3d9ms6lo0aI6ffp0kmOOhqbFzx+KTeMctDlz5qhbt26KiYnRoUOHNHz4cM2fP1/ly5fX66+/nuK5np6e6tmzp6ZOnapNmzZp5cqVGjZsWIpzmeIVKlRIvXv3Tpi7dPbsWQ0aNEjffvutnn766QwpQpGZKNwAAMh+zpyRZs6Uhg1LPkGKZ7NJzz0nrVwp7dwp1a1rJkuA1eLn1klJi5DEfz91quXrJUm3eos+//xzSdJXX32lmJgY9evXz65HZOzYsfLx8dGOHTs0f/58vfnmmxo3blzC/vSKTyrOnz/v8LijYgfvvPOO/v33X82aNUsrVqzQ1KlT9b///U9jx45VhQzoYUscl6P7G4ahc+fO3XGuTkbx8PBQ5cqVtWjRIpUpU0bjx49PUrnOkf79+ysuLk5du3ZVXFxcuku5BwQE6KuvvpK3t7d2796d7EK1zoIkCQCQ/UyZYiZHAwak/pxmzaRt26Q8eaT69aVEla0Ay3TqJC1YIBUvbr8/KMjcb+E6SYlVqlRJ9evX144dO7R7927NnDkzoUR4YkePHlXFihVVtmxZu/3h4eH6888/031/Pz8/lSpVSkeOHNHZs2eTHF+/fn2SffElx+OLM8QzDEMbN25M0t79v2Q0LT05NWrUkCSHZcF//fVXRUVFqXr16qm+Xkbw8fHRW2+9JcMwUlUAolKlSqpXr55Onz6t+vXrq2LFium+t7e3tzw9PdN9flYiSQIAZC8XL5pD6AYNkv6bG5FqpUpJmzZJ998vdewovfGG42FOQFbq1Ek6flxas0YKCzO/HjvmNAlSvPgehueee04HDhxQq1atksznCQkJ0ZEjR+x6VqKiojRgwADdvHnzru7fq1cv3bhxQ6+99prd/p9//tnhfKT42DZs2GC3f+LEidq7d2+S9vEV+U6dOpXqmLp37y4PDw9NmTJFZ86cSdh/48aNhMp1ffv2TfX1MkqHDh1Us2ZNrVixwmECebsZM2Zo0aJFCT2FKXn77bd1MJmqju+//76uXLmiChUqJJQKd1bMSQIAZC/vvSfFxZnry6SHr6/5G/rXX5defVXavdscupcnT8bGCaSFu7vZ2+nEHnvsMQ0dOjShF8bRsKzBgwdr8ODBqlGjhrp06aKYmBitWLFChmGoWrVqdzVPZcSIEVq4cKE+/fRT7du3T02aNNGpU6f0zTffqG3btvrhhx/s2j/77LOaOXOmOnfurK5du6pgwYLasmWLfvvtN4ftK1SooGLFimnu3Lny9vZWUFCQbDabBg8enFCs4nalS5fWpEmT9OKLL6pq1arq2rWr8uTJo++//16HDh1Shw4dEsqjZ7WxY8eqffv2eu2115Isnnu7SpUqqVKlSqm67ldffaXhw4fr3nvvVb169VSkSBFdunQp4dnmypVL06dPT3JeSiXAJalbt24ZNgwyNUiSAADZx+XL0rvvSk8/LRUunP7ruLlJY8ZIVapIffpIjRpJixdLd1HlCsju8ubNq65du2rmzJkqUKCAOnbsmKTNwIED5enpqffee0+ffvqp8uXLp7Zt2yo0NFSPPvroXd0/T548WrdunUaPHq1Fixbpt99+U+XKlTVv3jxFREQkSXpq1Kihn3/+Wa+88ooWLlwod3d3NWzYUBs3btR3332XpL27u7sWLlyokSNHas6cObp8+bIkqWfPnskmSZL0wgsvqEyZMpoyZYq+/vpr3bhxQ+XKldPbb7+t559//o4V5jJLu3btVLt2ba1du1arV69WixYtMuS6M2fO1Pfff6/Vq1dr+fLlOnfunNzd3RUSEqIBAwZo2LBhSYZbSuYwxnHjxiV73erVq2dpkmT7rx56thUZGSl/f39FRERk2cQ4AIBF3n5bGj1aOnpU+m/Rxru2e7fUoYN09ar07bdmCXHgP1FRUTp27JhKlSp1V4UHANyd1P5dTG1uwJwkAED2EBVlJkm9e2dcgiRJVauaBR0qV5ZatDDXpAEAZGskSQCA7OGLL6SzZ6URIzL+2oUKST//bA7je/ZZs2T4XU4yBwA4L5IkAIDri4mRJk2SHn1UKlcuc+7h6Sl98IHZk/Tpp2YFvAsXMudeAABLkSQBAFzfvHlmSeTRozP/Xk8/La1eLe3fL9WpY85ZAgBkKyRJAADXFhcnhYZKDz0kZdWijI0bm/OU8ueXGjQwCzoAALINkiQAgGv7/ntp3z7p5Zez9r4hIdKGDVLbtlKXLtLYsWbCBgBweayTBABwXYYhTZggNWki3Xdf1t8/Tx5zqF+1atIrr5hD77780lyQFgDgsuhJAgC4rjVrpK1bs74XKTGbTfq//5OWLJFWrJAaNjTnRwEAXBZJEgDAdU2YINWoIT3wgNWRSO3bS1u2SNeumQUd1qyxOiIAQDqRJAEAXNOvv0qrVpm9SDab1dGYKlc2e7Zq1DBLhH/wgTkkEADgUkiSAACuKTRUKl9eeuQRqyOxV6CAtGyZNGiQuT3zjHTjhtVRAQDSwNIkafr06apatar8/Pzk5+enBg0aaNmyZQnHmzVrJpvNZrc9++yzFkYMAHAKe/eac4BGjZLc3a2OJikPD2nqVGnGDOmLL6SWLaXz562OCgCQSpYmSUFBQZo4caJ27Nih7du3q0WLFurQoYP27duX0Oapp55SeHh4wjZ58mQLIwYAOIWJE6USJaQePayOJGX9+klr10qHD0u1a0u//251RACAVLA0SWrXrp0eeughlS1bVuXKldP48ePl6+urLVu2JLTJnTu3AgICEjY/Pz8LIwYAWO7PP6W5c6WXXpI8Pa2O5s4aNJC2b5eKFDHLlM+bZ3VEgMuz2Wxq1qyZ1WEgG3OaOUmxsbGaO3eurl69qgYNGiTsnz17tgoVKqQqVapo9OjRunbtWorXiY6OVmRkpN0GAMhG3nxTKlhQ6t/f6khSLyhIWr/enD/VrZtZMpyFZ+Hibp8ScafNldweu4eHh4oWLaqHH35YK1eudHjO2LFjE9oPHz482WuPHDkyod3YsWOTHP/hhx/Utm1bFSlSRJ6engk/Bz/xxBNasmSJXdtZs2bd8bn37dv3bh5FjmX5YrJ79uxRgwYNFBUVJV9fXy1atEiVKlWSJHXv3l0hISEqVqyYdu/erZEjR+rQoUNauHBhstcLDQ3VuHHjsip8AEBWCg835/mMGyflymV1NGmTK5f09dfmwrOjRkl79pjfM0ICqRAba+bZ4eFSYKDUuLH10/HGjBmTZN/UqVMVERHh8FhGOnDggHLnzp2p9yhYsKAGDRokSYqKitK+ffv0ww8/6IcfflBYWJgef/xxh+d5eHjo66+/1sSJE+XhYf+jdkxMjL788kt5eHgoJiYmybnjxo3T2LFjlTt3bj388MMqWbKkYmJitG/fPs2bN09//PGHOnTokOS8li1bqlGjRg7jqV69eho/OSRJhsWio6ONw4cPG9u3bzdGjRplFCpUyNi3b5/DtqtWrTIkGUeOHEn2elFRUUZERETCdurUKUOSERERkVkfAQCQVYYPNww/P8O4dMnqSO7ODz+Yn6NiRcM4fNjqaHAXrl+/buzfv9+4fv16pt3j228NIyjIMMx68uYWFGTudzYhISGGE/x4edckGeXLl0+yf86cOYYkIyQkJMmxMWPGGJKMdu3aGZKMRYsWJWmzZMkSQ5LRvn17Q5IxZsyYhGPHjh0z3NzcjODgYOP06dNJzr127ZqxZs0au30zZ840JBmhoaFp/YjZTmr/LkZERKQqN7B8uJ2Xl5fKlCmjWrVqKTQ0VNWqVdO0adMctq1Xr54k6ciRI8lez9vbO6FaXvwGAMgG/vlHmj7dLKvt7291NHfnoYfMdZ5iY6W6daUVK6yOCE5q4UKpSxfpr7/s958+be5PYXCN0zh+/HjCsK8DBw7okUceUcGCBWWz2XT8+HFJ0qJFi/T444+rTJkyyp07t/z9/dW4cWN9++23Dq/paE5S3759ZbPZdOzYMb377ruqUKGCvL29FRISonHjxikuA4a4PvbYY8qTJ49OnDihv//+22GbTp06KV++fJoxY0aSYzNmzFD+/Pn1iIOlC7Zu3aq4uDh16tRJxYoVS3I8V65czMPKQpYnSbeLi4tTdHS0w2M7d+6UJAUGBmZhRAAAp/Dee+Y8niFDrI4kY1SoYCZKdetKDz5olgxn4VkkEhtrvu6OXov4fUOHmu1cwZEjR1S/fn1duHBBffv2VZ8+feTl5SVJGj16tPbt26dGjRppyJAhevTRR3Xo0CF16dJF7733Xpru89JLL+n1119XgwYNEpaOGTt2rF599dUM/Ty3D6WL5+Pjo8cff1zLli3TuXPnEvafO3dOP/zwgx5//HH5+PgkOa9gwYKSpMOHD2donEgfS+ckjR49Wm3atFGJEiV0+fJlhYWFae3atVq+fLmOHj2qsLAwPfTQQypYsKB2796tYcOGqUmTJqpataqVYQMAstqVK9K0adJTT5lV4rKLfPmkH34w5ygNGybt2iV99JHk7W11ZMgA165JBw+m//zt25P2ICVmGNKpU9Lnn5sV5tOjQgUpk6f2JNi4caNee+01h3PHf/zxR91zzz12+65cuaKGDRvq1VdfVf/+/VM9B+m3337T7t27E36p/uqrr6ps2bJ67733NGbMmITELD3ii4xVrlxZ+fLlS7Zd//79NX36dH355Zd66aWXJElffvmlYmJi1L9/f/3xxx9JzqlXr55KlCihH3/8UQ8//LC6deumunXrqmzZsncsfLFy5UpFRUU5PNatWzdVqFAh9R8SkixOks6fP6/evXsrPDxc/v7+qlq1qpYvX677779fp06d0sqVKzV16lRdvXpVwcHB6ty5s1555RUrQwYAWOGTT6TLl6UUKka5LHd3s2Jf1apmEnjwoDmGilETLu/gQalWrcy/zzPPpP/cHTukmjUzLpaUBAQE6P/+7/8cHrs9QZIkX19f9e3bVy+++KK2bdumpk2bpuo+r776qt2oo0KFCqlDhw764osvdOjQId17772pus7ff/+dUH0uceEGX19fTZ8+PcVza9WqpapVq2rmzJkJSdLMmTNVrVo11axZ02GS5Ovrq8WLF6tXr14JBSIkJQw9fOKJJxwO05OkVatWadWqVQ6PVa9enSQpHSxNkj7//PNkjwUHB2vdunVZGA0AwClFR0tvvSX17i0FB1sdTebp1UsqX17q2FGqU0datMj8CpdVoYKZhKTX9u2pS4A+/vjuepKySrVq1ZLtxTl//rwmTpyoZcuW6cSJE7p+/brd8TNnzqT6PrUcZKZBQUGSpEuXLqX6OhcvXkzS6+Xr66sVK1aofv36dzz/iSee0NChQ7V582ZJZkW+5Obdx6tRo4b27NmjzZs3a82aNdqxY4c2bNigpUuXaunSperRo4e++uqrJD1LoaGhGjVqVKo/G+7M8hLgAACk6IsvpLNnpZEjrY4k89Wta/5k/MgjZo3nzz+XevSwOiqkU+7cd9dLU62a9PrrZpEGR/OSbDZzCa7+/a0vB54aRYsWdbj/n3/+UZ06dXTy5Endd999atWqlfLlyyd3d3ft3LlTS5YsSXa+uiOOinbFzx+KTcMErvLly+vgf+MlL126pMWLF2vAgAF65JFHtH37dhUvXjzF83v27KkRI0YkFHDw8vJSj1T8fbbZbGrYsKEaNmwoSTIMQ0uWLFHv3r01e/Zsde7cOdkeJWQcpyvcAABAgpgYadIks4xXuXJWR5M1ihWT1q2THntM6tlTGjHCdWbmI0O5u5tT8SQzIUos/vupU10jQZKU7Lyazz//XCdPntTrr7+uDRs26L333tPrr7+usWPHpqrHJivky5dPffv21fvvv6+zZ89q4MCBdzynYMGC6tChg+bNm6d58+apY8eOCcUZ0sJms6ljx44aNmyYJGn16tVpvgbSjiQJAOC8vvlG+vNPafRoqyPJWj4+0qxZ0pQp0ttvS+3aSWkYJoTso1MnacEC6fZOi6Agc3+nTtbElZGOHj0qSQ4XSV2/fn1Wh5OiJ554QjVr1tSSJUu0adOmVLW/fPmyLl++rCeeeOKu7u3r63tX5yNtSJIAAM4pLk4KDZXatJFq1LA6mqxns5kV75YtkzZvlurXlw4dsjoqWKBTJ+n4cWnNGikszPx67Fj2SJAkKSQkRJK0YcMGu/1hYWH68ccfrQgpWTabTWPGjJGkVJUUf+CBB7R48WItXrxY999/f4ptt27dqi+//NJhlboLFy7os88+kyQ1atQoHZEjrZiTBABwTkuXSnv3mgvI5mQPPCBt3Sp16CDVqyfNmWMmjshR3N2l7LqOaK9evTRp0iQNHjxYa9asUUhIiHbt2qVVq1apU6dOWuhkK+a2b99etWrV0urVq7Vu3boUq+65ubk57CFz5MyZM+rTp48GDRqkJk2aqEKFCvLw8NCJEye0dOlSXblyRW3bttWjjz6a5NyUSoAHBAQkrBeF1CNJAgA4H8OQJkwwixfwW1OpbFlpyxape3fp4YeliRPNcuh3WDsFcAVBQUFat26dRowYoZUrVyomJkY1a9bUzz//rFOnTjldkiSZi9O2a9dOr776qn755ZcMuWbLli319ddfa/ny5frtt9+0ceNGXblyRfnz51e9evXUvXt39enTR25uSQeCpVQCvFq1aiRJ6WAzjOy9vHdkZKT8/f0VERHhsNoJAMAJrVkjtWhhDjV78EGro3EesbHSq6+awxB79jTXj8qVy+qocrSoqCgdO3ZMpUqVko+Pj9XhADlWav8upjY3YE4SAMD5TJhgzkNq3drqSJyLu7v5bMLCzFn7TZua9aEBABmKJAkA4Fy2bpVWrjQr2jGczLHHH5c2bJDCw81VRLdssToiAMhWSJIAAM4lNNRcEym7lO7KLLVqmQvP3nOP2aP0xRdWRwQA2QZJEgDAeezbJy1eLI0a5TorZFqpaFFp9WqpVy+pb1/phRfMBXgBAHeF6nYAAOcxcaIUHCz16GF1JK7D21v69FOpWjVzXaW9e6V586T8+a2ODABcFj1JAADncOyYuQbQSy9JXl5WR+NabDZp8GBp+XJpxw6pbl3pwAGrowIAl0WSBABwDm++KRUoIPXvb3UkrqtlS2nbNrN3qV49c0FeZIlsvqIK4PQy+u8gSRIAwHrh4dKMGeZwsdy5rY7Gtd1zj7R5s7nOVPv2ZiEMfoDPNO7/zZ27efOmxZEAOVv830H3DJrPSpIEALDeO++YvR/PPWd1JNlD3rzSwoXSK69IL78sde8uXbtmdVTZkqenp7y9vRUREUFvEmARwzAUEREhb29veXp6Zsg1KdwAALDWP/9I06ebc2r8/a2OJvtwc5P+9z/p3nvNyneNG5uVA4ODrY4s2ylUqJBOnz6tv/76S/7+/vL09JSNNb6ATGcYhm7evKmIiAhduXJFxYsXz7BrkyQBAKz1/vtm2eqhQ62OJHt69FGpbFmpY0dz4dmFC6X77rM6qmzFz89PkvT333/r9OnTFkcD5Dze3t4qXrx4wt/FjECSBACwzpUr0rRp0lNPSUWKWB1N9lW9ulnQoUsXqXlz6cMPpSeftDqqbMXPz09+fn66efOmYmNjrQ4HyDHc3d0zbIhdYiRJAADrfPKJFBkpDR9udSTZX+HC0ooV0pAhZlK6a5c0ZYqUCT9c5GSenp6Z8gMbgKxF4QYAgDWio6W335Z69ZJKlLA6mpzBy8uc/zV9uvTRR1Lr1tLFi1ZHBQBOhyQJAGCNL780S3+PHGl1JDnPs89KK1dKe/ZIdeqYXwEACUiSAABZLyZGmjRJ6txZKl/e6mhypqZNzXlKefNKDRpIixZZHREAOA2SJABA1ps/Xzp6VBo92upIcraSJaVNm6Q2baROncyS4XFxVkcFAJYjSQIAZK24OGnCBOnBB6WaNa2OBnnySN98YyZIY8ZIXbuaVQcBIAcjSQIAZK0ffpD27pVeftnqSBDPZpNefdUccrd8ubmO0vHjVkcFAJYhSQIAZB3DkMaPlxo1kho3tjoa3K5jR2nzZunyZbOgw7p1VkcEAJYgSQIAZJ21a6Vff6UXyZlVqWIWdKhaVWrVyiwXDgA5DEkSACDrhIZK1aub85HgvAoWlH76SRowQHruObNk+I0bVkcFAFnGw+oAAAA5xLZt0ooVZpEAm83qaHAnnp7Su++aPUrPPSft3y99+61UuLDVkQFApqMnCQCQNUJDpXLlzFLTcB1PPimtWSMdOiTVri3t3Gl1RACQ6UiSAACZb/9+s3LayJGSu7vV0SCt7rvP7AksVMj88/z5VkcEAJmKJAkAkPkmTpSCgqSePa2OBOlVooS0fr3Uvr25ltJrr7HwLIBsizlJAIDMdeyYFBYmTZkieXlZHQ3uRu7c5n/LatXMCoW7d0tffSXlzWt1ZACQoehJAgBkrjfflPLnN+e2wPXZbNKoUdJ330mrV0sNGkhHj1odFQBkKJIkAEDmOXtWmjFDGjbM7IVA9vHww+aaV9HRUt260qpVVkcEABmGJAkAkHneeUfy9jZLSCP7qVhR2rrVrHrXurX03nuSYVgdFQDcNZIkAEDm+Pdf6cMPzQQpXz6ro0FmyZ9f+uEHacgQ6fnnpaeeMnuXAMCFkSQBADLH++9LMTHS0KFWR4LM5uEhvf22NGuWWcihRQvp3DmrowKAdCNJAgBkvCtXpKlTzWINRYtaHQ2ySp8+0rp10p9/mkPwduywOiIASBeSJABAxvv0UykyUho+3OpIkNXq15e2b5cCA6VGjaQ5c6yOCADSjCQJAJCxoqOlt94yF44NCbE6GliheHGzR6lLF6l7d2n0aCk21uqoACDVWEwWAJCxvvpKCg+XRo60OhJYKVcu6csvzYVnR46U9uyRZs+W/P2tjgwA7oieJABAxomJkSZOlDp3lipUsDoaWM1mM4dc/vCDtGGDORTv8GGrowKAOyJJAgBknAULpKNHzeFVQLwHHzQXnjUMc+HZn3+2OiIASJGlSdL06dNVtWpV+fn5yc/PTw0aNNCyZcsSjkdFRWngwIEqWLCgfH191blzZ52jpCgAOCfDkCZMMBcVrVnT6mjgbMqXNxOlBg2kNm2kKVNYeBaA07I0SQoKCtLEiRO1Y8cObd++XS1atFCHDh20b98+SdKwYcP0/fffa/78+Vq3bp3OnDmjTp06WRkyACA5P/xgzjt5+WWrI4Gz8veXvv/eHIL34otS375SVJTVUQFAEjbDcK5f4xQoUEBvvvmmunTposKFCyssLExdunSRJB08eFAVK1bU5s2bVb9+/VRdLzIyUv7+/oqIiJCfn19mhg4AOZdhSA0bSu7u0vr15lwUICWzZ5vraFWrJi1cKBUrZnVEAHKA1OYGTjMnKTY2VnPnztXVq1fVoEED7dixQzdv3lSrVq0S2lSoUEElSpTQ5s2bk71OdHS0IiMj7TYAQCZbt07assXsRSJBQmr06GEm1H/9ZS48u3Wr1REBQALLk6Q9e/bI19dX3t7eevbZZ7Vo0SJVqlRJZ8+elZeXl/Lly2fXvmjRojp79myy1wsNDZW/v3/CFhwcnMmfAACgCRPMHoE2bayOBK6kdm1p2zapZEmpSROzfDwAOAHLk6Ty5ctr586d+vXXXzVgwAD16dNH+/fvT/f1Ro8erYiIiITt1KlTGRgtACCJ7dulFSvoRUL6BAZKa9aYi8727m3OV2LhWQAWs3wxWS8vL5UpU0aSVKtWLW3btk3Tpk3TY489phs3bujSpUt2vUnnzp1TQEBAstfz9vaWt7d3ZocNAIgXGiqVLWuujQSkh7e39PnnZm/kiy9Ke/dKc+ZI+fNbHRmAHMrynqTbxcXFKTo6WrVq1ZKnp6dWrVqVcOzQoUM6efKkGjRoYGGEAIAE+/ebk+5HjjSLNgDpZbNJQ4ZIP/1kzk+qV086eNDqqADkUJb2JI0ePVpt2rRRiRIldPnyZYWFhWnt2rVavny5/P391b9/f73wwgsqUKCA/Pz8NHjwYDVo0CDVle0AAJls0iQpKEjq1cvqSJBdtGplJkkdOpiJ0pw50kMPWR0VgBzG0iTp/Pnz6t27t8LDw+Xv76+qVatq+fLluv/++yVJ77zzjtzc3NS5c2dFR0erdevW+vDDD60MGQAQ7/hxs4zz229LXl5WR4PspEwZafNmqWdP6eGHzSGdI0Yw5w1AlnG6dZIyGuskAUAmGThQ+uYbM1nKk8fqaJAdxcVJr70mjR9vFnb47DMpVy6rowLgwlxunSQAgAs5e9acaD90KAkSMo+bm/TGG9K8edKiRVLjxua6SgCQyUiSAABpN3WqOcRu4ECrI0FO0LWrtHGjdP68ubbSpk1WRwQgmyNJAgCkzb//Sh9+KD33nHTbgt9ApqlRw1yTq2xZqXlzacYMqyMCkI2RJAEA0uaDD6SbN6Vhw6yOBDlNkSLSqlVS375S//7mcM+YGKujApANWb6YLADAhVy9ag61699fKlrU6miQE3l5SR99ZC48+/zz0r595pylAgWsjgxANkJPEgAg9T79VIqIkF56yepIkJPZbOZwz5Urpd9/l+rWNZMlAMggJEkAgNSJjpbeekvq0UMKCbE6GkBq1kzatk3KnVuqX1/67jurIwKQTZAkAQBS56uvpDNnpJEjrY4EuKVUKbPa3QMPSB07mmsqZe8lIAFkAZIkAMCdxcZKkyZJnTpJFStaHQ1gz9dXmj9fGjNGeuUVqVs3c/4cAKQTSRIA4M4WLJCOHJFGj7Y6EsAxNzczSfr2W+mHH6RGjaSTJ62OCoCLIkkCAKTMMKQJE8zhTLVqWR0NkLJOnczhd5cumQvPrl9vdUQAXBBJEgAgZT/+KO3eLb38stWRAKlTtapZ0KFyZallS+mTT6yOCICLIUkCACTPMMyJ8A0bSk2aWB0NkHqFCkk//yw9/bT0zDPSwIHmIsgAkAosJgsASN4vv0ibN0tLl5pr0wCuxNNTev99s2dp4EBp/36zwEOhQlZHBsDJ0ZMEAEjehAnmD5gPPWR1JED6Pf20tHq1ueBsnTrm8FEASAFJEgDAsR07zOFKL79MLxJcX+PG0vbtUr585vDRhQutjgiAEyNJAgA4FhoqlSkjdelidSRAxihRQtqwQWrbVurcWRo7VoqLszoqAE6IOUkAgKQOHDB/0/7JJ5K7u9XRABknTx5p7lypWjXp//7PHHr35ZfmgrQA8B96kgAASU2aJBUrJvXqZXUkQMaz2cxhpEuWSCtWmMPvjh2zOioAToQkCQBg7/hx6euvpeHDJW9vq6MBMk/79tKWLdK1a2ZBhzVrrI4IgJMgSQIA2HvrLXNy+1NPWR0JkPkqV5a2bpVq1JDuv1/64ANzfTAAORpJEgDglrNnpc8+k4YONeduADlBgQLSsmXSoEHm9swz0o0bVkcFwEIkSQCAW6ZOlby8zIU3gZzEw8N8/2fMkL74QmrZUjp/3uqoAFiEJAkAYLp0SfrwQ+m556T8+a2OBrBGv37S2rXS4cNS7drS779bHREAC5AkAQBMH3xgDjEaOtTqSABrNWhgLjxbpIh0333SvHlWRwQgi5EkAQCkq1fNoUb9+0sBAVZHA1gvKEhav1565BGpWzfplVdYeBbIQVhMFgBgFmv491/ppZesjgRwHrlymeXwq1WTRo0yF579+mvJz8/qyABkMnqSACCnu3FDevNNqUcPqWRJq6MBnIvNJo0YIS1dKq1bZw7FO3LE6qgAZDKSJADI6b76SjpzxvxNOQDHHnpI+vVXKSZGqltXWrnS6ogAZCKSJADIyWJjpUmTzHkXFStaHQ3g3CpUMBOlevWk1q2ladNYeBbIpkiSACAn+/Zbs9Tx6NFWRwK4hnz5zKF3L7xgVoLs31+KjrY6KgAZjCQJAHIqw5AmTJDuv99cDwZA6ri7m/P4vvxSCguTmjeXzp61OioAGYgkCQByqmXLpF27pJdftjoSwDX16iX98ot04oT5i4bt262OCEAGIUkCgJzIMKTx481KXU2bWh0N4Lrq1pW2bTPXVWrc2OxZAuDySJIAICdav17atMnsRbLZrI4GcG3Fiklr10qPPWaW0h850iyKAsBlsZgsAOREEyZIVatKbdtaHQmQPfj4SDNnmgvPDh8u7d1r9ir5+1sdGYB0oCcJAHKaHTuk5cvNinb0IgEZx2aThg0z5/tt2mSWCv/jD6ujApAOJEkAkNOEhkplykiPPmp1JED29MAD0tatkpubOWfpp5+sjghAGpEkAUBOcvCgtHChOWfC3d3qaIDsq2xZacsWs5hD27bSW2+x8CzgQkiSACAnmTRJCgw0SxcDyFx+ftLixeYvJV56SerdW4qKsjoqAKlAkgQAOcWJE9LXX5uTyr29rY4GyBnc3c1CKXPmSN9+KzVpIp0+bXVUAO6AJAkAcoq33jIrbT31lNWRADlPt27Shg1SeLhUp470669WRwQgBSRJAJATnDsnffaZNGSI5OtrdTRAzlSzprR9u3TPPWaP0hdfWB0RgGSQJAFATjB1quThIQ0aZHUkQM5WtKi0apU5L7BvX+mFF6SYGKujAnAbFpMFgOzu0iXpgw+k556T8ue3OhoA3t7Sp59K1atLQ4eaC8/Om8ffT8CJWNqTFBoaqjp16ihv3rwqUqSIOnbsqEOHDtm1adasmWw2m9327LPPWhQxALigDz+UbtwwF7kE4BxsNrNn9+efzQWe69aVDhywOioA/7E0SVq3bp0GDhyoLVu2aMWKFbp586YeeOABXb161a7dU089pfDw8IRt8uTJFkUMAC7m2jXpnXekJ56QAgKsjgbA7Vq0kLZtM3uX6tWTli61OiIAsni43U+3rUA9a9YsFSlSRDt27FCTJk0S9ufOnVsB/OMOAGn32WfSv/+aa7QAcE733CNt3myuo9S+vTR+vDRqlNnbBMASTlW4ISIiQpJUoEABu/2zZ89WoUKFVKVKFY0ePVrXrl1L9hrR0dGKjIy02wAgR7pxQ3rzTal7d6lUKaujAZCSvHnNdZRefVV6+WXz7238zzuxsdLateZaS2vXmt8DyFROU7ghLi5OQ4cO1X333acqVaok7O/evbtCQkJUrFgx7d69WyNHjtShQ4e0cOFCh9cJDQ3VuHHjsipsAHBeX38t/fWX+RtpAM7PzU0aN066916pTx+pcWPpmWek1183/y7HCwqSpk2TOnWyLlYgm7MZhmFYHYQkDRgwQMuWLdOGDRsUFBSUbLvVq1erZcuWOnLkiEqXLp3keHR0tKKjoxO+j4yMVHBwsCIiIuTn55cpsQOA04mNlSpWlKpUkZL5pRIAJ7Zzp/TAA9KFC0mPxQ/DW7CARAlIo8jISPn7+98xN3CK4XaDBg3S0qVLtWbNmhQTJEmqV6+eJOnIkSMOj3t7e8vPz89uA4Ac59tvpcOHpdGjrY4EQHrce6/k6en4WPzvt4cOZegdkEksHW5nGIYGDx6sRYsWae3atSqVijHzO3fulCQFBgZmcnQA4KIMQwoNle6/X6pTx+poAKTH+vXSmTPJHzcM6dQp6dlnpaZNpRIlpOBgqXhxycsr6+IEsilLk6SBAwcqLCxMS5YsUd68eXX27FlJkr+/v3LlyqWjR48qLCxMDz30kAoWLKjdu3dr2LBhatKkiapWrWpl6ADgvH76yRyqs3q11ZEASK/w8NS1mzPHrGIZz2Yzy/3HJ02OvhYubM5/ApAsS+ck2ZIpbTlz5kz17dtXp06dUs+ePbV3715dvXpVwcHBeuSRR/TKK6+kehhdascdAkC20bixFBMjbdpECWHAVa1dKzVvfud2a9aYPcanTpnbyZOOv16/fuscLy8zYUouiQoOlviZCdlUanMDpynckFlIkgDkKOvXS02aSN99J7VrZ3U0ANIrNlYqWVI6ffrWHKTEbDazyt2xY5K7e8rXMgzp4sWUk6jTp6W4uFvn+PunnEQFBTGsDy6JJOk/JEkAcpQ2bcwfdnbuZDgN4OoWLpS6dDH/nPjHtcyobhcTYw7xSy6JOnnSTLQSx1C0aMrD+ooU4f9DcDqpzQ2cZp0kAMBd+u03cz5SWBg/mADZQadOZiI0ZEjSdZKmTs3Y8t8eHreG4CXn2rXkh/X9+KP5NX4BXMnsaQoKSrlHyt8/4z4DkIHoSQKA7OLRR6Xff5cOHjR/4AGQPcTGmkNpw8OlwEBz3uGdhthZwTCkf/6587C+xGXL/fzuPKzP29u6z4Rsh54kAMhJDh4010b6+GMSJCC7cXeXmjWzOoo7s9mkggXNrXp1x21iYqSzZx0nUdu3m0MM//7b/pw7DesrWpTec2Q4/iUFgOxg8mTzN8y9e1sdCQAkz8PD7B0KCkq+zbVr5vBCRz1RP/1k/jnxsD5Pz9QN66PaJ9KAJAkAXN3Jk9JXX0mTJjEsBYDry51bKlfO3BwxDOnffx0nUcePm0MT//rLflhf3rx3Htbn45MlHw+ugSQJAFzdW2+Z4/qfftrqSAAg89lsUoEC5latmuM2sbHJD+v77Tdp8WLpwgX7c4oUufOwPmecC4ZMQZIEAK7s/Hnp00+l0aMlX1+rowEA5+DuLhUvbm4NGjhuc/168sP6fv7Z/PPVq7faxw8VTKlHKl8+hvVlEyRJAODKpk41/+EeNMjqSADAteTKJZUta26OGIZ06VLy1fo2bjSTrJiYW+f4+qacRAUHM6zPRZAkAYCrunRJ+uADacAAc9gJACDj2GxS/vzmVrWq4zaxsdK5c46TqJ07pe++M3v8EytcOOVhfQEBDOtzAiRJAOCqPvxQio6Whg2zOhIAyJnc3aVixcytfn3HbaKikh/Wt3Kl+ecrV2619/Awhwmm1COVPz/D+jIZSRIAuKJr18yhdv36maW/AQDOycdHKlPG3BwxDCkiIvlhfZs3m0nWzZu3zsmT587D+nLlyprPl02RJAGAK/r8c3Nl+5desjoSAMDdsNnMgg/58kn33uu4TVxc8sP6du+Wli41jydWqJDj5Cn+z4GBWbP4eGysWZY9PNy8Z+PGLjGc0GYYhmF1EJkpMjJS/v7+ioiIkJ+fn9XhAMDdu3HD/I1k06bm+kgAAERHJz+s7+RJc7t8+Vb7+KGCKc2PKlDg7ob1LVwoDRlixhUvKEiaNk3q1Cn9170Lqc0N6EkCAFcze7b5j96oUVZHAgBwFt7eUunS5paclIb1bd1q/jnxsL5cuVJOooKDzcV/HVm4UOrSxRxOmNjp0+b+BQssS5RSg54kAHAlsbFSpUrmtmiR1dEAALKTuDizGp+jJCr+69mz9ucULJg0eSpe3CwqdPuCvfFsNrNH6dixLB96R08SAGRHCxdKf/zBMDsAQMZzczNLkAcESHXrOm4THW32BjlKotatM79GRKR8H8Mw261fLzVrluEfIyOQJAGAqzAMacIEqVWr5P/xAgAgM3l7S/fcY27JmTFD6t//ztcKD8+4uDIYSRIAuIrly83FCVevtjoSAACSl1IClZgTL2HhZnUAAIBUmjBBqlfPaYcmAAAgySzzHRSUfGU8m82cv9S4cdbGlQYkSQDgCtavN7eXX2aVdQCAc3N3N8t8S0n/zYr/fupUp14viSQJAFxBaKhUpYr08MNWRwIAwJ116mSW+S5e3H5/UJDTl/+WmJMEAM7v99+lZcvM9ZHc+N0WAMBFdOokdehgjoQIDzfnIDVu7NQ9SPFIkgDA2YWGmpNgu3a1OhIAANLG3d0l59KSJAGAMzt0yByW8NFHkgf/ywYAICswbgMAnNmkSeaifn36WB0JAAA5BkkSADirkyelr76SXnzRXLwPAABkCZIkAHBWb78t5c0rPfOM1ZEAAJCjkCQBgDM6f1769FNpyBDJ19fqaAAAyFFIkgDAGU2bZpb7HjzY6kgAAMhxSJIAwNlEREjvvy8NGCAVKGB1NAAA5DgkSQDgbD78UIqKkl54wepIAADIkUiSAMCZXLsmvfOO9MQT5srkAAAgy5EkAYAzmTFDunhReuklqyMBACDHIkkCAGdx44Y0ebL0+OPSPfdYHQ0AADkWSRIAOIuwMOnUKWnUKKsjAQAgRyNJAgBnEBsrTZwodeggValidTQAAORoHlYHAACQtGiRdOiQ9MUXVkcCAECOR08SAFjNMKQJE6SWLaV69ayOBgCAHI+eJACw2vLl0u+/S6tWWR0JAAAQPUkAYL3QUKluXal5c6sjAQAAoicJAKy1YYP0yy/S4sWSzWZ1NAAAQPQkAYC1QkOlypWldu2sjgQAAPyHniQAsMrOndKPP0pffy258TsrAACcBf8qA4BVQkOlUqWkxx6zOhIAAJCIpUlSaGio6tSpo7x586pIkSLq2LGjDh06ZNcmKipKAwcOVMGCBeXr66vOnTvr3LlzFkUMABnkjz+k+fOlkSMlDzr1AQBwJpYmSevWrdPAgQO1ZcsWrVixQjdv3tQDDzygq1evJrQZNmyYvv/+e82fP1/r1q3TmTNn1KlTJwujBoAMMGmSFBAg9eljdSQAAOA2NsMwjNQ2Pn/+vIoUKZLs8ZiYGP3222+qW7duuoK5cOGCihQponXr1qlJkyaKiIhQ4cKFFRYWpi5dukiSDh48qIoVK2rz5s2qX7/+Ha8ZGRkpf39/RUREyM/PL11xAUCGOnVKuucec7jd8OFWRwMAQI6R2twgTT1JgYGBOn/+fML39957r06dOpXw/cWLF9WgQYN0hGuKiIiQJBUoUECStGPHDt28eVOtWrVKaFOhQgWVKFFCmzdvdniN6OhoRUZG2m0A4FTeflvKm1d65hmrIwEAAA6kKUm6vdPp+PHjunnzZoptUisuLk5Dhw7VfffdpypVqkiSzp49Ky8vL+XLl8+ubdGiRXX27FmH1wkNDZW/v3/CFhwcnK54ACBTXLggffKJ9PzzZqIEAACcTobPSbKlczHEgQMHau/evZo7d+5d3X/06NGKiIhI2BL3dAGA5aZNM8t9Dx5sdSQAACAZTlFSadCgQVq6dKl++eUXBQUFJewPCAjQjRs3dOnSJbvepHPnzikgIMDhtby9veXt7Z3ZIQNA2kVESO+/Lz37rFSwoNXRAACAZKSpJ8lms+ny5cuKjIxURESEbDabrly5ku75P4ZhaNCgQVq0aJFWr16tUqVK2R2vVauWPD09tWrVqoR9hw4d0smTJ+9q7hMAWGL6dOn6demFF6yOBAAApCBN1e3c3NzshtMZhuHw+9jY2FRd77nnnlNYWJiWLFmi8uXLJ+z39/dXrly5JEkDBgzQjz/+qFmzZsnPz0+D/xuismnTplTdg+p2AJzCtWtSyZJSp07SRx9ZHQ0AADlSanODNA23W7NmzV0Hltj06dMlSc2aNbPbP3PmTPXt21eS9M4778jNzU2dO3dWdHS0WrdurQ8//DBD4wCATDdjhnTxojRihNWRAACAO0hTT5IroicJgOVu3pTKlJEaNZJmz7Y6GgAAcqxM6UmKiYlRbGysXWGEc+fO6aOPPtLVq1fVvn17NWrUKP1RA0B2FBYmnTwpjRpldSQAACAV0tST1K9fP3l5eenjjz+WJF2+fFmVK1dWVFSUAgMDtX//fi1ZskQPPfRQpgWcVvQkAbBUbKxUubJUvry0ZInV0QAAkKOlNjdIU3W7jRs3qnPnzgnff/nll4qNjdXhw4e1a9cuvfDCC3rzzTfTHzUAZDeLF0uHDkmjR1sdCQAASKU0JUmnT59W2bJlE75ftWqVOnfuLH9/f0lSnz59tG/fvoyNEABclWFIEyZILVpI9etbHQ0AAEilNCVJPj4+un79esL3W7ZsUb169eyOX7lyJeOiAwBX9vPP0m+/SS+/bHUkAAAgDdKUJFWvXl1fffWVJGn9+vU6d+6cWrRokXD86NGjKlasWMZGCACuasIEqW5dsycJAAC4jDRVt3vttdfUpk0bffPNNwoPD1ffvn0VGBiYcHzRokW67777MjxIAHA5GzdKv/wiLVokJVp0GwAAOL80JUlNmzbVjh079PPPPysgIECPPvqo3fHq1aurbt26GRogALik0FCpUiWpfXurIwEAAGnEYrIAkNF27pRq1JC++krq2dPqaAAAwH8yZTHZX375JVXtmjRpkpbLAkD2MnGiVLKk1K2b1ZEAAIB0SFOS1KxZM9n+G1ufXAeUzWZTbGzs3UcGAK7ojz+kb76RPvxQ8kjT/2IBAICTSNO/4Pnz51fevHnVt29f9erVS4UKFcqsuADANU2eLBUtKvXta3UkAAAgndJUAjw8PFyTJk3S5s2bde+996p///7atGmT/Pz85O/vn7ABQI506pT05ZfSiy9KPj5WRwMAANIpTUmSl5eXHnvsMS1fvlwHDx5U1apVNWjQIAUHB+v//u//FBMTk1lxAoDze/ttyddXeuYZqyMBAAB34a6r2x07dkz9+/fXunXrdOHCBRUoUCCjYssQVLcDkCUuXDCLNQwfLo0bZ3U0AADAgdTmBmnqSYoXHR2tsLAwtWrVSlWqVFGhQoX0ww8/OF2CBABZ5t13zUVjn3/e6kgAAMBdSlPhhq1bt2rmzJmaO3euSpYsqX79+umbb74hOQKQs0VGSu+9Zw6zK1jQ6mgAAMBdSlOSVL9+fZUoUULPP/+8atWqJUnasGFDknbtWWEeQE4yfbp0/br0wgtWRwIAADJAmuYkubndeXSes62TxJwkAJnq+nVzLlLHjtLHH1sdDQAASEFqc4M09STFxcXdsc21a9fSckkAcG0zZkh//y2NGGF1JAAAIIOkq3CDI9HR0ZoyZYruueeejLokADi3mzfNxWMfe0wqXdrqaAAAQAZJU5IUHR2t0aNHq3bt2mrYsKEWL14sSZoxY4ZKlSqld955R8OGDcuMOAHA+cyZI508KY0aZXUkAAAgA6VpTtLIkSP18ccfq1WrVtq0aZMuXLigfv36acuWLXr55Zf16KOPyt3dPTPjTTPmJAHIFHFxUuXKUtmy0nffWR0NAABIhUyZkzR//nx9+eWXat++vfbu3auqVasqJiZGu3btks1mu+ugAcBlLF4sHTwozZxpdSQAACCDpaknycvLS8eOHVPx4sUlSbly5dLWrVt17733ZlqAd4ueJAAZzjCkOnUkPz9p9WqrowEAAKmUKT1JsbGx8vLyunWyh4d8fX3THyUAuKIVK6QdO8yvAAAg20lTkmQYhvr27Stvb29JUlRUlJ599lnlyZPHrt3ChQszLkIAcDYTJpg9SS1bWh0JAADIBGlKkvr06WP3fc+ePTM0GABweps2SevWSQsXSszFBAAgW0rTnCRXxJwkABmqXTvp6FFp717JLcOWmgMAAFkgU+YkAUCOtmuXtHSp9OWXJEgAAGRj/CsPAKk1caJUsqTUrZvVkQAAgExETxIApMbhw9I330jvvy95elodDQAAyET0JAFAakyeLBUuLPXrZ3UkAAAgk5EkAcCd/PWX9MUX0osvSj4+VkcDAAAyGUkSANzJ229LefJIzz5rdSQAACALkCQBQEr+/lv65BNp8GApb16rowEAAFmAJAkAUvLuu+bX55+3Ng4AAJBlSJIAIDmRkdJ770nPPCMVKmR1NAAAIIuQJAFAcj76SLp61SzYAAAAcgySJABw5Pp1acoUqW9fqXhxq6MBAABZiCQJAByZOVO6cEEaMcLqSAAAQBYjSQKA2928aS4e+9hjUpkyVkcDAACymIfVAQCA05kzRzpxQvruO6sjAQAAFqAnCQASi4uTJk6UHn5YqlrV6mgAAIAF6EkCgMSWLJEOHJA+/9zqSAAAgEUs7Un65Zdf1K5dOxUrVkw2m02LFy+2O963b1/ZbDa77cEHH7QmWADZn2FIEyZIzZpJDRpYHQ0AALCIpT1JV69eVbVq1fTEE0+oU6dODts8+OCDmjlzZsL33t7eWRUegJxm5Upp+3bp55+tjgQAAFjI0iSpTZs2atOmTYptvL29FRAQkEURAcjRJkyQateWWrWyOhIAAGAhpy/csHbtWhUpUkTly5fXgAEDdPHixRTbR0dHKzIy0m4DgDvatElau1Z6+WXJZrM6GgAAYCGnTpIefPBBffnll1q1apUmTZqkdevWqU2bNoqNjU32nNDQUPn7+ydswcHBWRgxAJcVGipVrCh16GB1JAAAwGI2wzAMq4OQJJvNpkWLFqljx47Jtvnzzz9VunRprVy5Ui1btnTYJjo6WtHR0QnfR0ZGKjg4WBEREfLz88vosAFkB7t3S9WqSV98IfXubXU0AAAgk0RGRsrf3/+OuYFT9yTd7p577lGhQoV05MiRZNt4e3vLz8/PbgOAFE2cKIWESI8/bnUkAADACbjUOkl//fWXLl68qMDAQKtDAZBdHDkizZsnvfee5OlpdTQAAMAJWJokXblyxa5X6NixY9q5c6cKFCigAgUKaNy4cercubMCAgJ09OhRjRgxQmXKlFHr1q0tjBpAtjJ5slS4sNSvn9WRAAAAJ2HpcLvt27erRo0aqlGjhiTphRdeUI0aNfTaa6/J3d1du3fvVvv27VWuXDn1799ftWrV0vr161krCUDGOH1amjVLeuEFKVcuq6MBAABOwmkKN2SW1E7OApADvfCCNHOmdOKExP8fAADI9rJl4QYAyDB//y19/LE0aBAJEgAAsEOSBCBnevdd8+uQIdbGAQAAnA5JEoCc5/Jls5rd009LhQpZHQ0AAHAyJEkAcp6PPpKuXpVefNHqSAAAgBMiSQKQs0RFSW+/LfXpIwUFWR0NAABwQiRJAHKWmTOlCxekESOsjgQAADgpkiQAOcfNm+bisV27SmXLWh0NAABwUh5WBwAAWWbuXOn4cWnJEqsjAQAAToyeJAA5Q1ycFBoqtW0rVa1qdTQAAMCJ0ZMEIGf47jvpwAHps8+sjgQAADg5epIAZH+GIU2YIDVtKjVsaHU0AADAydGTBCD7W7VK2rZNWr7c6kgAAIALoCcJQPY3YYJUq5Z0//1WRwIAAFwAPUkAsrfNm6U1a6Rvv5VsNqujAQAALoCeJADZW2ioVKGC1LGj1ZEAAAAXQU8SgOxrzx7p+++lWbMkN34nBAAAUoefGgBkXxMnSiVKSN27Wx0JAABwIfQkAciejh6V5s6V3n1X8vS0OhoAAOBC6EkCkD1NniwVKiQ98YTVkQAAABdDkgQg+zl92pyH9MILUq5cVkcDAABcDEkSgOxnyhQzORowwOpIAACACyJJApC9XLwoffSRNHiw5OdndTQAAMAFkSQByF7efVcyDOn5562OBAAAuCiSJADZx+XLZpL09NNS4cJWRwMAAFwUSRKA7OPjj6WrV6UXX7Q6EgAA4MJIkgBkD1FR0ttvS717S8HBVkcDAABcGEkSgOxh1izp/Hlp5EirIwEAAC6OJAmA64uJkSZNkh59VCpb1upoAACAi/OwOgAAuGtz50rHj0uLF1sdCQAAyAboSQLg2uLipNBQ6aGHpGrVrI4GAABkA/QkAXBt330n7d8vffKJ1ZEAAIBsgp4kAK7LMMxepCZNpPvuszoaAACQTdCTBMB1rV4tbd0q/fST1ZEAAIBshJ4kAK5rwgSpZk3pgQesjgQAAGQj9CQBcE1btpg9SQsWSDab1dEAAIBshJ4kAK4pNFSqUEF65BGrIwEAANkMPUkAXM+ePWZVu5kzJTd+1wMAADIWP10AcD0TJ0olSkg9elgdCQAAyIboSQLgWv78U5o7V5o2TfL0tDoaAACQDdGTBMC1TJ4sFSok9e9vdSQAACCbIkkC4DrOnDHnIQ0bJuXKZXU0AAAgmyJJAuA6pkwxk6MBA6yOBAAAZGMkSQBcw8WL0kcfSYMGSf7+VkcDAACyMZIkAK7hvfekuDhpyBCrIwEAANkcSRIA53f5svTuu9JTT0mFC1sdDQAAyOYsTZJ++eUXtWvXTsWKFZPNZtPixYvtjhuGoddee02BgYHKlSuXWrVqpcOHD1sTLADrfPyxmSgNH251JAAAIAewNEm6evWqqlWrpg8++MDh8cmTJ+vdd9/VRx99pF9//VV58uRR69atFRUVlcWRArBMVJRZsKF3byk42OpoAABADmDpYrJt2rRRmzZtHB4zDENTp07VK6+8og4dOkiSvvzySxUtWlSLFy9Wt27dsjJUAFb54gvp7Flp5EirIwEAADmE085JOnbsmM6ePatWrVol7PP391e9evW0efPmZM+Ljo5WZGSk3QbARcXESJMmSY8+KpUrZ3U0AAAgh3DaJOns2bOSpKJFi9rtL1q0aMIxR0JDQ+Xv75+wBTM8B3Bd8+ZJx45Jo0dbHQkAAMhBnDZJSq/Ro0crIiIiYTt16pTVIQFIj7g4KTRUeughqXp1q6MBAAA5iKVzklISEBAgSTp37pwCAwMT9p87d07VU/iBydvbW97e3pkdHoDM9v330r595gKyAAAAWchpe5JKlSqlgIAArVq1KmFfZGSkfv31VzVo0MDCyABkOsOQJkyQGjeWGjWyOhoAAJDDWNqTdOXKFR05ciTh+2PHjmnnzp0qUKCASpQooaFDh+qNN95Q2bJlVapUKb366qsqVqyYOnbsaF3QADLfmjXS1q3SsmVWRwIAAHIgS5Ok7du3q3nz5gnfv/DCC5KkPn36aNasWRoxYoSuXr2qp59+WpcuXVKjRo30008/ycfHx6qQAWSFCROkGjWk1q2tjgQAAORANsMwDKuDyEyRkZHy9/dXRESE/Pz8rA4HwJ38+qtUv740f77UpYvV0QAAgGwktbmB085JApBDhYZK5ctLjzxidSQAACCHctrqdgByoL17pSVLpJkzJXd3q6MBAAA5FD1JAJzHxIlScLDUvbvVkQAAgByMniQAzuHPP6U5c6SpUyUvL6ujAQAAORg9SQCcw+TJUsGCUv/+VkcCAAByOJIkANYLDzfnIQ0bJuXObXU0AAAghyNJAmC9KVMkHx/pueesjgQAAIAkCYDF/vlHmj5dGjRI8ve3OhoAAACSJAAWe+89KS5OGjLE6kgAAAAkkSQBsNLly9K0adKTT0pFilgdDQAAgCSSJABW+uQTM1EaPtzqSAAAABKQJAGwRnS09PbbUq9eUokSVkcDAACQgCQJgDW++EI6e1YaOdLqSAAAAOyQJAHIejEx0qRJUpcuUvnyVkcDAABgx8PqAADkQN98I/35p7RggdWRAAAAJEFPEoCsFRcnhYZKbdpINWpYHQ0AAEAS9CQByFpLl0p790offmh1JAAAAA7RkwQg6xiGNH681KiR1Lix1dEAAAA4RE8SgKyzZo20dav0449WRwIAAJAsepIAZJ3QUKl6denBB62OBAAAIFn0JAHIGlu3SitXmpXtbDarowEAAEgWPUkAskZoqFSunNSpk9WRAAAApIieJACZb98+afFiacYMyd3d6mgAAABSRE8SgMw3caIUHCz16GF1JAAAAHdETxKAzPXnn9KcOdKUKZKXl9XRAAAA3BE9SQAy15tvSvnzS08+aXUkAAAAqUKSBCDzhIeb85CGDZNy57Y6GgAAgFQhSQKQed55R/LxkZ57zupIAAAAUo0kCUDm+Ocfafp0aeBAKV8+q6MBAABINZIkAJnj/felmBhp6FCrIwEAAEgTkiQAGe/KFWnaNOmpp6QiRayOBgAAIE1IkgBkvE8+kSIjpeHDrY4EAAAgzUiSAGSs6Gjprbeknj2lEiWsjgYAACDNSJIAZKwvvpDOnpVGjrQ6EgAAgHQhSQKQcWJipMmTpc6dpQoVrI4GAAAgXTysDgBANjJ/vnT0qPTNN1ZHAgAAkG70JAHIGHFx0oQJ0oMPSjVrWh0NAABAutGTBCBj/PCDtHev9OGHVkcCAABwV+hJAnD3DEMaP1667z6pcWOrowEAALgr9CQBuHtr10q//mr2JgEAALg4epIA3L0JE6Rq1aQ2bayOBAAA4K7RkwTg7mzbJq1cKc2bJ9lsVkcDAABw1+hJAnB3QkOlsmXNtZEAAACyAXqSAKTf/v3SokXS559L7u5WRwMAAJAh6EkCkH4TJ0pBQVLPnlZHAgAAkGGcOkkaO3asbDab3VahQgWrwwIgSceOSWFh0vDhkpeX1dEAAABkGKcfble5cmWtXLky4XsPD6cP2bHYWGn9eik8XAoMNNeSYXgSXNmbb0r580tPPml1JAAAABnK6TMODw8PBQQEWB3G3Vm4UBoyRPrrr1v7goKkadOkTp2siwtIr/BwacYM6dVXpTx5rI4GAAAgQzn1cDtJOnz4sIoVK6Z77rlHPXr00MmTJ1NsHx0drcjISLvNUgsXSl26KPavM1qrppqjblqrpor9K1zq0sU8Driad94xh9gNHGh1JAAAABnOZhiGYXUQyVm2bJmuXLmi8uXLKzw8XOPGjdPp06e1d+9e5c2b1+E5Y8eO1bhx45Lsj4iIkJ+fX2aHbC82VipZUgv/qqMhmqa/FJxwKEinNE1D1Sl4mzm3g6F3cBX//iuVKCENGmSW/wYAAHARkZGR8vf3v2Nu4NRJ0u0uXbqkkJAQTZkyRf3793fYJjo6WtHR0QnfR0ZGKjg42Jokae1aLWz+rrpogcyHfKvjzqY4SdICdVGnopskf3/zN/OenubX5LaUjmf0MU9PFgeFKfGcuhUrzIINJ05IRYtaHRkAAECqpTZJcvo5SYnly5dP5cqV05EjR5Jt4+3tLW9v7yyMKnmxp89qiKYlSZAkyZCbbIrTUE1Vh3pD5V6utHTjhv128+atP1+7lvwxR+fdvJkxH8LTM2sTs7s5192dpC4zOJpT5+srbdzInDoAAJAtuVSSdOXKFR09elS9evWyOpRUWX+hgt0Qu9sZctMpldD65q+p2dDqGXtzw3CcSN0pucqIY1FRUmRk2s6Ljb37z2yzOVdP3J2Ouzn9lMCEOXW6vcP56lVz/4IFJEoAACDbceokafjw4WrXrp1CQkJ05swZjRkzRu7u7nr88cetDi1VwgtXTVW7x0KrqcFaqUqVW1u5cne59IzNduuHcVcQG2ufNGVFMhe/XbmS8nm3n5toOOddcXd3rp6424+5u0vPP580QZLMfTabNHSo1KEDc+oAAEC24tRJ0l9//aXHH39cFy9eVOHChdWoUSNt2bJFhQsXtjq0VAksnrqegiZNbIqIMCsqh4eb+zw8pPLl7ROnKlWkUqWy6c+j7u7m5uNjdSR3ZhhmUmdFQnfjhnT9etrOy6ihl46ew6lT5lylZs0y5x4AAAAWcOokae7cuVaHcFcaNzaXQzr9lyFDSefK2GQoKNimuXNvJT4XL0r79pnb3r3m9vPPZkExScqVS6pUyT5xqlzZvA/TcbKIzWZmsR4eUu7cVkdzZ/FDL9OalK1aJU2deufrx2f2AAAA2YRTJ0muzt3dXC+2SxebbDJkGLeyGJvNkGTT1Kn2PUMFC0pNmphbPMOQzp69lTTFbwsWmFNDJMnPL2mvU5Uqkot0uiEzJR56mZaFX319U5ckBQamOzQAAABn5FIlwNMjtWX+MpOj4mDBwebPn3cz5z0uzqzCfHvydPCg2REgSUWKJE2cKlc2kyogRf+t86XTpx3PS7LZzC5M1vkCAAAuIluuk5QezpAkSfbLzAQGmkPxMuvnyps3pSNH7Ifs7d0rHT5sJlaSuRbo7clThQrmcD4gQXx1O8k+UYof20l1OwAA4EJIkv7jLEmSM4iKMnuZbu95OnHCPO7mJpUunTR5KlvWLHqGHCqzukIBAACyGEnSf0iS7iwyUtq/P2nydO6cedzT0+xluj15KlnSNZb6QQbIyq5QAACATEKS9B+SpPT7+++kQ/b27JEiIszjuXOb85sSz3WqUkUqVoxKewAAAHA+JEn/IUnKWIYhnTmTtNdp3z5z+R5JypfPcaW9ggUtDR0AAAA5HEnSf0iSskZcnFnk7Pbk6dChW2uZBgQkTZwqVZLy5rU2dgAAAOQMJEn/IUmy1s2bZlW925OnI0duFUsrWTJpifIKFSQfH0tDBwAAQDZDkvQfkiTndO2a40p7p06Zx93czKp6t/c8lSkjebAEMgAAANIhtbkBP27CErlzSzVrmltiERH2xSL27ZOmT5fOnzePe3lJFSsmTZ5KlKDSHgAAADIGSRKcir+/1LChuSV2/nzSSnvff2+WL5ckX1/HlfYCAqi0BwAAgLQhSYJLKFLE3Jo3v7XPMMz1TRMnTr//Ls2ebS6cK0kFCiTtdapc2dwPAAAAOMKcJGQ7sbHSn3/aD9mLr7QXE2O2KVbMcaW9PHmsjR0AAACZh8IN/yFJQrwbN6Q//khaLOLPP29V2rvnHvvhelWqSOXLS97e1sYOAACAu0fhBuA2Xl63Ep/Erl6VDhywT5y+/FI6fdo87u4ulSuXtOepdGnzGAAAALIXepKAZPz7762hevFf9+yRLl40j/v4OK60FxxMsQgAAABnRE8ScJfy55caNTK3eIZhVtq7fcjeokXSlStmm7x5kw7Zq1LFLDxB8gQAAOD8SJKANLDZpKJFza1ly1v7DUM6edI+cdq+XfrqKyk62mxTqJDjSnv58lnyUQAAAJAMhtsBmSgmxr7SXvz2xx9mFT5JCgpKmjxVrGguuAsAAICMQ3W7/5AkwRlFR5slyW9Pno4dM4/bbGZhiNuH7ZUrZxagAAAAQNoxJwlwYt7eUtWq5pbYlSvS/v32idPMmdKZM+ZxDw+zJPntPU+lSlFpDwAAIKOQJAFOxNdXqlvX3BL7559bFfbit59/NivwSVKuXOZiuLcnT8WLZ0yxiNhYaf16KTxcCgyUGjcmKQMAANkXw+0AF2UY0tmzSYfs7dtnrv0kSf7+jivtFS6c+vssXCgNGSL99detfUFB0rRpUqdOGfuZAAAAMhNzkv5DkoScJi5OOnEiaeJ04IB044bZpkgRx5X2bv8rsnCh1KWLmZAlFt87tWABiRIAAHAdJEn/IUkCTDEx0pEjSXueDh82EytJKlHiVtJUqZI0YoS5LpQjNpvZo3TsGEPvAACAayBJ+g9JEpCyqCjp4MGkydOJE6k7f80aqVmzTA0RAAAgQ1DdDkCq+PhI1aubW2IzZkj9+9/5/I4dpQoVpJIlpZAQc0v8Z1/fDA8ZAAAgU5EkAXDonntS165jR3Po3fHj0tat0qlT5tC+eAULOk6e4v+cL1/GVOADAADIKCRJABxq3Nicc3T6dNLCDdKtOUmff24/Jyk21lzX6cQJczt+/Naff/jB/Bodfat93ry3EiZHSVThwiRRAAAga5EkAXDI3d0s892li5mkJE6U4pOWqVOTFm1wd5eCg82tUaOk1zUMsxhE4uQp/s9r1phfr1y51T5XrluJk6NEKjBQcnPL0I8OAAByOAo3AEiRo3WSgoPNBCkzyn8bhrlIrqMkKn77559b7T09zXiSmxMVFGS2AQAAoLrdf0iSgLsXGyutXy+Fh5s9N40bW1v2+/LlpAlU4kTq3Llbbd3cpOLFkx/OV6KEWbwCAABkfyRJ/yFJAnKe69elkyeTJk/xf759nlVAQMrFJajQBwBA9kAJcAA5Vq5cUvny5ubIzZvm8EFHvVDbtiWt0FegQPLD+UqWpEIfAADZDUkSgBzH01MqVcrcHImNNYcWOuqFWrbM/BoVdat93rzJ90KVLEmFPgAAXA1JEgDcxt3dLPgQFJRyhT5Hw/nWrTP/fPnyrfa5cplzn5JLpAIDrZ3jBQAA7JEkAUAa2WxS0aLmVrdu0uPxFfocVefbtk1asMBxhT5HvVBU6AMAIOuRJAFABrPZzHlMBQpINWo4bpO4Ql/iROrAAXNIX3IV+hz1RlGhDwCAjEWSBAAWyJtXqlLF3ByJijIr9DmaF/XLL2aFvri4W+2LFk2+uERIiHk/AACQOiRJAOCEfHykcuXMzZH4Cn2O5kVt325W6Lt581b7AgWSnxMVEiLlz09xCQAA4pEkAYALSm2FPkfzolKq0JdcIlWkCEkUACDnIEkCgGwocYW+++5LetwwpAsXkh/Od/y4fYU+Hx/74Xu3J1JU6AMAZCckSQCQA9lsZu9QkSLJV+i7dMnxcL4dO6SFC6WLF2+19/AwK/QlN5wvOJgKfQAA10GSBABIwmYz5ynlzy9Vr+64zZUrjofzHTgg/fSTdPbsrbZublKxYskP5ytRwlxPKjPExkrr15vDDwMDpcaN6fWCa+Edhitz1ffXJZKkDz74QG+++abOnj2ratWq6b333lNdR7/6BABkGV9fqXJlc3MkvkKfo0QquQp9Kc2LSk+FvoULpSFDzCIX8YKCpGnTpE6d0n49IKvxDsOVufL7azMMw7A6iJTMmzdPvXv31kcffaR69epp6tSpmj9/vg4dOqQiRYrc8fzIyEj5+/srIiJCfn5+WRAxACA1Elfoc5RInTzpuEJfcknU7RX6Fi6UunQxhw4mFt9mwQLn/0caORvvMFyZs76/qc0NnD5JqlevnurUqaP3339fkhQXF6fg4GANHjxYo0aNuuP5JEkA4JpiY80he47mRcV/TVyhz9f3VsIUHCzNmSNFRDi+ts1m/jbz2DHXGPaBnCc21nyfE/8GPjHeYTgzZ35/U5sbOPVwuxs3bmjHjh0aPXp0wj43Nze1atVKmzdvdnhOdHS0oqOjE76PjIzM9DgBABnP3V0qXtzcGjZMejy+Qt/tSdSJE9Ly5cknSPHnnjplVu1zc8u0jwCkW1ycFBOT/HHeYTiz1L6/69dLzZplWVhp4tRJ0t9//63Y2FgVLVrUbn/RokV18OBBh+eEhoZq3LhxWREeAMBCiSv01aljf2zOHKl79ztfo2dPqXbtzIkPuBvbt0uzZt25He8wnFFq39/w8EwPJd2cOklKj9GjR+uFF15I+D4yMlLBwcEWRgQAyGqBgalr16eP8/4WEznb2rWp+yGTdxjOKLXvb2r/X20Fp+6gLVSokNzd3XXu3Dm7/efOnVNAQIDDc7y9veXn52e3AQBylsaNzfHuiQs5JGazmfOWGjfO2riA1OIdhivLDu+vUydJXl5eqlWrllatWpWwLy4uTqtWrVKDBg0sjAwA4Mzc3c0Ss1LSf6Tjv586lQnvcF68w3Bl2eH9deokSZJeeOEFffrpp/riiy904MABDRgwQFevXlW/fv2sDg0A4MQ6dTJLzBYvbr8/KIjSyXANvMNwZa7+/jp9CXBJev/99xMWk61evbreffdd1atXL1XnUgIcAHI2V13tHYjHOwxX5mzvb7ZZJ+lukSQBAAAAkFKfGzj9cDsAAAAAyEokSQAAAACQCEkSAAAAACRCkgQAAAAAiZAkAQAAAEAiJEkAAAAAkAhJEgAAAAAkQpIEAAAAAImQJAEAAABAIiRJAAAAAJAISRIAAAAAJEKSBAAAAACJkCQBAAAAQCIeVgeQ2QzDkCRFRkZaHAkAAAAAK8XnBPE5QnKyfZJ0+fJlSVJwcLDFkQAAAABwBpcvX5a/v3+yx23GndIoFxcXF6czZ84ob968stlslsYSGRmp4OBgnTp1Sn5+fpbGkh3xfDMXzzdz8XwzF883c/F8Mx/POHPxfDOXMz1fwzB0+fJlFStWTG5uyc88yvY9SW5ubgoKCrI6DDt+fn6WvyDZGc83c/F8MxfPN3PxfDMXzzfz8YwzF883cznL802pBykehRsAAAAAIBGSJAAAAABIhCQpC3l7e2vMmDHy9va2OpRsieebuXi+mYvnm7l4vpmL55v5eMaZi+ebuVzx+Wb7wg0AAAAAkBb0JAEAAABAIiRJAAAAAJAISRIAAAAAJEKSBAAAAACJkCRloF9++UXt2rVTsWLFZLPZtHjx4jues3btWtWsWVPe3t4qU6aMZs2alelxuqq0Pt+1a9fKZrMl2c6ePZs1AbuQ0NBQ1alTR3nz5lWRIkXUsWNHHTp06I7nzZ8/XxUqVJCPj4/uvfde/fjjj1kQretJz/OdNWtWknfXx8cniyJ2PdOnT1fVqlUTFips0KCBli1bluI5vL+pl9bny/ubfhMnTpTNZtPQoUNTbMf7mz6peb68v2kzduzYJM+rQoUKKZ7jCu8vSVIGunr1qqpVq6YPPvggVe2PHTumtm3bqnnz5tq5c6eGDh2qJ598UsuXL8/kSF1TWp9vvEOHDik8PDxhK1KkSCZF6LrWrVungQMHasuWLVqxYoVu3rypBx54QFevXk32nE2bNunxxx9X//799fvvv6tjx47q2LGj9u7dm4WRu4b0PF/JXJk88bt74sSJLIrY9QQFBWnixInasWOHtm/frhYtWqhDhw7at2+fw/a8v2mT1ucr8f6mx7Zt2/Txxx+ratWqKbbj/U2f1D5fifc3rSpXrmz3vDZs2JBsW5d5fw1kCknGokWLUmwzYsQIo3Llynb7HnvsMaN169aZGFn2kJrnu2bNGkOS8e+//2ZJTNnJ+fPnDUnGunXrkm3TtWtXo23btnb76tWrZzzzzDOZHZ7LS83znTlzpuHv7591QWVD+fPnNz777DOHx3h/715Kz5f3N+0uX75slC1b1lixYoXRtGlTY8iQIcm25f1Nu7Q8X97ftBkzZoxRrVq1VLd3lfeXniQLbd68Wa1atbLb17p1a23evNmiiLKn6tWrKzAwUPfff782btxodTguISIiQpJUoECBZNvw/qZfap6vJF25ckUhISEKDg6+42/tcUtsbKzmzp2rq1evqkGDBg7b8P6mX2qer8T7m1YDBw5U27Ztk7yXjvD+pl1anq/E+5tWhw8fVrFixXTPPfeoR48eOnnyZLJtXeX99bA6gJzs7NmzKlq0qN2+okWLKjIyUtevX1euXLksiix7CAwM1EcffaTatWsrOjpan332mZo1a6Zff/1VNWvWtDo8pxUXF6ehQ4fqvvvuU5UqVZJtl9z7y5yvlKX2+ZYvX14zZsxQ1apVFRERobfeeksNGzbUvn37FBQUlIURu449e/aoQYMGioqKkq+vrxYtWqRKlSo5bMv7m3Zpeb68v2kzd+5c/fbbb9q2bVuq2vP+pk1any/vb9rUq1dPs2bNUvny5RUeHq5x48apcePG2rt3r/LmzZukvau8vyRJyLbKly+v8uXLJ3zfsGFDHT16VO+8846++uorCyNzbgMHDtTevXtTHE+M9Evt823QoIHdb+kbNmyoihUr6uOPP9brr7+e2WG6pPLly2vnzp2KiIjQggUL1KdPH61bty7ZH+SRNml5vry/qXfq1CkNGTJEK1asoDhAJkjP8+X9TZs2bdok/Llq1aqqV6+eQkJC9M0336h///4WRnZ3SJIsFBAQoHPnztntO3funPz8/OhFyiR169blh/8UDBo0SEuXLtUvv/xyx9+WJff+BgQEZGaILi0tz/d2np6eqlGjho4cOZJJ0bk+Ly8vlSlTRpJUq1Ytbdu2TdOmTdPHH3+cpC3vb9ql5fnejvc3eTt27ND58+ftRjjExsbql19+0fvvv6/o6Gi5u7vbncP7m3rpeb634/1Nm3z58qlcuXLJPi9XeX+Zk2ShBg0aaNWqVXb7VqxYkeIYb9ydnTt3KjAw0OownI5hGBo0aJAWLVqk1atXq1SpUnc8h/c39dLzfG8XGxurPXv28P6mQVxcnKKjox0e4/29eyk939vx/iavZcuW2rNnj3bu3Jmw1a5dWz169NDOnTsd/gDP+5t66Xm+t+P9TZsrV67o6NGjyT4vl3l/ra4ckZ1cvnzZ+P33343ff//dkGRMmTLF+P33340TJ04YhmEYo0aNMnr16pXQ/s8//zRy585tvPTSS8aBAweMDz74wHB3dzd++uknqz6CU0vr833nnXeMxYsXG4cPHzb27NljDBkyxHBzczNWrlxp1UdwWgMGDDD8/f2NtWvXGuHh4QnbtWvXEtr06tXLGDVqVML3GzduNDw8PIy33nrLOHDggDFmzBjD09PT2LNnjxUfwaml5/mOGzfOWL58uXH06FFjx44dRrdu3QwfHx9j3759VnwEpzdq1Chj3bp1xrFjx4zdu3cbo0aNMmw2m/Hzzz8bhsH7e7fS+nx5f+/O7dXXeH8z1p2eL+9v2rz44ovG2rVrjWPHjhkbN240WrVqZRQqVMg4f/68YRiu+/6SJGWg+JLTt299+vQxDMMw+vTpYzRt2jTJOdWrVze8vLyMe+65x5g5c2aWx+0q0vp8J02aZJQuXdrw8fExChQoYDRr1sxYvXq1NcE7OUfPVZLd+9i0adOEZx3vm2++McqVK2d4eXkZlStXNn744YesDdxFpOf5Dh061ChRooTh5eVlFC1a1HjooYeM3377LeuDdxFPPPGEERISYnh5eRmFCxc2WrZsmfADvGHw/t6ttD5f3t+7c/sP8by/GetOz5f3N20ee+wxIzAw0PDy8jKKFy9uPPbYY8aRI0cSjrvq+2szDMPIun4rAAAAAHBuzEkCAAAAgERIkgAAAAAgEZIkAAAAAEiEJAkAAAAAEiFJAgAAAIBESJIAAAAAIBGSJAAAAABIhCQJAAAAABIhSQIAAACAREiSAABOoW/fvrLZbLLZbPL09FTRokV1//33a8aMGYqLi7M6PABADkKSBABwGg8++KDCw8N1/PhxLVu2TM2bN9eQIUP08MMPKyYmJtPue+PGjUy7NgDA9ZAkAQCchre3twICAlS8eHHVrFlTL7/8spYsWaJly5Zp1qxZkqRLly7pySefVOHCheXn56cWLVpo165ddtd54403VKRIEeXNm1dPPvmkRo0aperVqycc79u3rzp27Kjx48erWLFiKl++vCTp1KlT6tq1q/Lly6cCBQqoQ4cOOn78uN21P/vsM1WsWFE+Pj6qUKGCPvzww8x8JAAAC5AkAQCcWosWLVStWjUtXLhQkvToo4/q/PnzWrZsmXbs2KGaNWuqZcuW+ueffyRJs2fP1vjx4zVp0iTt2LFDJUqU0PTp05Ncd9WqVTp06JBWrFihpUuX6ubNm2rdurXy5s2r9evXa+PGjfL19dWDDz6Y0NM0e/Zsvfbaaxo/frwOHDigCRMm6NVXX9UXX3yRdQ8EAJDpbIZhGFYHAQBA3759denSJS1evDjJsW7dumn37t365JNP1LZtW50/f17e3t4Jx8uUKaMRI0bo6aefVv369VW7dm29//77CccbNWqkK1euaOfOnQn3+umnn3Ty5El5eXlJkr7++mu98cYbOnDggGw2myRzGF6+fPm0ePFiPfDAAypTpoxef/11Pf744wnXfuONN/Tjjz9q06ZNmfBUAABW8LA6AAAA7sQwDNlsNu3atUtXrlxRwYIF7Y5fv35dR48elSQdOnRIzz33nN3xunXravXq1Xb77r333oQESZJ27dqlI0eOKG/evHbtoqKidPToUV29elVHjx5V//799dRTTyUcj4mJkb+/f4Z8TgCAcyBJAgA4vQMHDqhUqVK6cuWKAgMDtXbt2iRt8uXLl6Zr5smTx+77K1euqFatWpo9e3aStoULF9aVK1ckSZ9++qnq1atnd9zd3T1N9wYAODeSJACAU1u9erX27NmjYcOGKSgoSGfPnpWHh4dKlizpsH358uW1bds29e7dO2Hftm3b7nifmjVrat68eSpSpIj8/PySHPf391exYsX0559/qkePHun+PAAA50eSBABwGtHR0Tp79qxiY2N17tw5/fTTTwoNDdXDDz+s3r17y83NTQ0aNFDHjh01efJklStXTmfOnNEPP/ygRx55RLVr19bgwYP11FNPqXbt2mrYsKHmzZun3bt365577knx3j169NCbb76pDh066H//+5+CgoJ04sQJLVy4UCNGjFBQUJDGjRun559/Xv7+/nrwwQcVHR2t7du3699//9ULL7yQRU8JAJDZSJIAAE7jp59+UmBgoDw8PJQ/f35Vq1ZN7777rvr06SM3N7Mg648//qj/+7//U79+/XThwgUFBASoSZMmKlq0qCQz2fnzzz81fPhwRUVFqWvXrurbt6+2bt2a4r1z586tX375RSNHjlSnTp10+fJlFS9eXC1btkzoWXryySeVO3duvfnmm3rppZeUJ08e3XvvvRo6dGimPhcAQNaiuh0AINu7//77FRAQoK+++srqUAAALoCeJABAtnLt2jV99NFHat26tdzd3TVnzhytXLlSK1assDo0AICLoCcJAJCtXL9+Xe3atdPvv/+uqKgolS9fXq+88oo6depkdWgAABdBkgQAAAAAibhZHQAAAAAAOBOSJAAAAABIhCQJAAAAABIhSQIAAACAREiSAAAAACARkiQAAAAASIQkCQAAAAASIUkCAAAAgET+H3+vwwXbAB2hAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimal Degree:  2\n"
     ]
    }
   ],
   "source": [
    "# Partition the training data into train and validation subsets for this experiment\n",
    "X_train_new, X_validation, y_train_new, y_validation = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "degreeList = [1,2,3,4,5]\n",
    "\n",
    "# Two lists to store train and validation MSE values for various models of varying complexity\n",
    "mse_train, mse_validation = [], []\n",
    "\n",
    "for degree in degreeList:\n",
    "\n",
    "    # Create a pipeline object: first add polynomials, then standardize, and finally create a Linear Regression model \n",
    "    model = make_pipeline(PolynomialFeatures(degree, include_bias=False), StandardScaler(), LinearRegression()) \n",
    "  \n",
    "    # Train the model\n",
    "    model.fit(X_train_new, y_train_new)\n",
    "       \n",
    "    # Make prediction \n",
    "    y_train_predicted = model.predict(X_train_new)\n",
    "    y_validation_predicted = model.predict(X_validation)\n",
    "    \n",
    "    \n",
    "    # Compute MSE and add to the list\n",
    "    mse_train.append(mean_squared_error(y_train_new, y_train_predicted))\n",
    "    mse_validation.append(mean_squared_error(y_validation, y_validation_predicted))\n",
    "   \n",
    "\n",
    "\n",
    "# Plot RMSE values for varying polynomial degree\n",
    "plt.figure(figsize=(10, 6))   \n",
    "plt.plot(degreeList, np.sqrt(mse_validation), \"ro-\", alpha=1.0, linewidth=1.0, label=\"Validation RMSE\")\n",
    "plt.plot(degreeList, np.sqrt(mse_train), \"bo-\", alpha=1.0, linewidth=1.0, label=\"Train RMSE\")    \n",
    "plt.legend(loc=\"best\", fontsize=14) \n",
    "plt.xlabel(\"Degree\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.title(\"RMSE for Varying Degree\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Find the value of the optimal degree for the polynomial that gives the smallest validation RMSE\n",
    "rmse_validation = np.sqrt(mse_validation)\n",
    "j = 0\n",
    "min_rmse = rmse_validation[j]\n",
    "optimal_degree = 1\n",
    "\n",
    "for i in degreeList:\n",
    "    if(rmse_validation[j] < min_rmse):\n",
    "        min_rmse = rmse_validation[j]\n",
    "        optimal_degree = i\n",
    "    j +=1\n",
    "    \n",
    "print(\"\\nOptimal Degree: \", optimal_degree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardize the Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on the training set only.\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Apply transform to both the training set and the test set.\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Apply the Regularized OLS Method (MAP) on the Optimal Polynomial Model\n",
    "\n",
    "\n",
    "There are three different regularized OLS models.\n",
    "\n",
    "- Ridge Regression ($l_2$ norm)\n",
    "- Lasso Regression ($l_1$ norm)\n",
    "- Elastic Net (it combines $l_1$ and $l_2$ priors as regularizer)\n",
    "\n",
    "We will use the OLS Ridge and Lasso Regression algorithms on the high-degree polynomial dataset.\n",
    "\n",
    "\n",
    "#### Using cross-validation we determine the optimal regularization (penalty) coefficients that produce the best generalization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression\n",
    "\n",
    "We will implement the Ridge Regression with Scikit-Learn using a closed-form solution. It uses a matrix factorization technique by André-Louis **Cholesky**. However, there are other solvers that we can choose from.\n",
    "\n",
    "We need to find optimal values for the following **two hyperparameters** of the Ridge regression model.\n",
    "\n",
    "- alpha : {float, array-like}, shape (n_targets)\n",
    "Regularization strength; must be a positive float. Regularization improves the conditioning of the problem and reduces the variance of the estimates. Larger values specify stronger regularization.\n",
    "\n",
    "- solver : {‘auto’, ‘svd’, ‘cholesky’, ‘lsqr’, ‘sparse_cg’, ‘sag’, ‘saga’}\n",
    "\n",
    "The solvers:\n",
    "1. ‘svd’ uses a Singular Value Decomposition of X to compute the Ridge coefficients. More stable for singular matrices than ‘cholesky’.\n",
    "2. ‘cholesky’ uses the standard scipy.linalg.solve function to obtain a closed-form solution.\n",
    "3. ‘sparse_cg’ uses the conjugate gradient solver as found in scipy.sparse.linalg.cg. As an iterative algorithm, this solver is more appropriate than ‘cholesky’ for large-scale data (possibility to set tol and max_iter).\n",
    "4. ‘lsqr’ uses the dedicated regularized least-squares routine scipy.sparse.linalg.lsqr. It is the fastest and uses an iterative procedure.\n",
    "5. ‘sag’ uses a Stochastic Average Gradient descent, and ‘saga’ uses its improved, unbiased version named SAGA. Both methods also use an iterative procedure, and are often faster than other solvers when both n_samples and n_features are large. Note that ‘sag’ and ‘saga’ fast convergence is only guaranteed on features with approximately the same scale. You can preprocess the data with a scaler from sklearn.preprocessing.\n",
    "6. ‘auto’ chooses the solver automatically based on the type of data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection: Hyperparameter Tuning\n",
    "\n",
    "\n",
    "We need to select the best model based on the optimal values of these hyperparameters. This process is called hyperparameter tuning.\n",
    "\n",
    "The best way to do hyperparameter tuning is to use **cross-validation**.\n",
    "\n",
    "We will use Scikit-Learn’s GridSearchCV to search the combinations of hyperparameter values that provide the best performance.\n",
    "\n",
    "We need to tell which hyperparameters we want the GridSearchCV to experiment with, and what values to try out. It will evaluate all the possible combinations of hyperparameter values, using cross-validation. \n",
    "\n",
    "\n",
    "### Important:\n",
    "\n",
    "The GridSearchCV takes an argument to define the scoring metric (performance measure). \n",
    "\n",
    "See the list of possible scoring functions:\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "\n",
    "For regression, we may use \"neg_mean_squared_error\" or \"explained_variance\" scoring function. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a High-Degree Polynomial Data Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Original Features:  13\n",
      "No. of Augmented Features:  104\n"
     ]
    }
   ],
   "source": [
    "# Variable that specifies the degree of the polynomial to be added to the feature vector\n",
    "poly_degree = optimal_degree\n",
    "\n",
    "\n",
    "# Add polynomial terms with the feature vector using the sklearn PolynomialFeatures class\n",
    "poly_features = PolynomialFeatures(degree=poly_degree, include_bias=False)\n",
    "X_train_poly = poly_features.fit_transform(X_train)\n",
    "\n",
    "\n",
    "print(\"No. of Original Features: \", X_train.shape[1])\n",
    "print(\"No. of Augmented Features: \", X_train_poly.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection Via Grid Search: Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 120 candidates, totalling 1200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mhasan2/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score (negative mean squared error): -12.422019\n",
      "Optimal Hyperparameter Values:  {'alpha': 0.9478947368421053, 'solver': 'saga'}\n",
      "\n",
      "\n",
      "CPU times: user 423 ms, sys: 173 ms, total: 595 ms\n",
      "Wall time: 3.91 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# The param_grid tells Scikit-Learn to evaluate all combinations of the hyperparameter values\n",
    "\n",
    "param_grid = {'alpha': np.linspace(0.01, 1.0, num=20), \n",
    "              'solver': [\"auto\", \"svd\", \"cholesky\", \"lsqr\", \"sparse_cg\", \"saga\"]}\n",
    "\n",
    "ridge = Ridge()\n",
    "\n",
    "ridge_cv = GridSearchCV(ridge, param_grid, scoring='neg_mean_squared_error', cv=10, verbose=1, n_jobs=-1)\n",
    "ridge_cv.fit(X_train_poly, y_train)\n",
    "\n",
    "\n",
    "params_optimal_ridge = ridge_cv.best_params_\n",
    "\n",
    "print(\"Best Score (negative mean squared error): %f\" % ridge_cv.best_score_)\n",
    "print(\"Optimal Hyperparameter Values: \", params_optimal_ridge)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select The Best Model for the Ridge Regressor\n",
    "\n",
    "Using the optimal hyperparameter values, create the best model.\n",
    "Then, fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal alpha:  0.9478947368421053\n",
      "Optimal alpha:  saga\n",
      "\n",
      "----------------------------- Model Evaluation -----------------------------\n",
      "\n",
      "Mean squared error: 6.42\n",
      "Coefficient of determination r^2 variance score [1 is perfect prediction]: 0.93\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "\n",
    "\n",
    "# Optimal model parameters\n",
    "ridge_alpha = ridge_cv.best_params_['alpha']\n",
    "print(\"Optimal alpha: \", ridge_alpha)\n",
    "\n",
    "ridge_solver = ridge_cv.best_params_['solver']\n",
    "print(\"Optimal alpha: \", ridge_solver)\n",
    "\n",
    "\n",
    "# Create a Ridge linear regression object\n",
    "lin_reg_ridge = Ridge(alpha=ridge_alpha, solver=ridge_solver)\n",
    "\n",
    "# Train the model\n",
    "lin_reg_ridge.fit(X_train_poly, y_train)\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n----------------------------- Model Evaluation -----------------------------\")\n",
    "\n",
    "# Make prediction \n",
    "y_train_predicted_ridge = lin_reg_ridge.predict(X_train_poly)\n",
    "\n",
    "\n",
    "print(\"\\nMean squared error: %.2f\"\n",
    "      % mean_squared_error(y_train, y_train_predicted_ridge))\n",
    "\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print(\"Coefficient of determination r^2 variance score [1 is perfect prediction]: %.2f\" % r2_score(y_train, y_train_predicted_ridge))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model Using Test Data: Ridge Regression\n",
    "\n",
    "We will use the optimal degree for the polynomial to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------- Test Model Evaluation -----------------------------\n",
      "\n",
      "Mean squared error: 14.15\n",
      "Coefficient of determination r^2 variance score [1 is perfect prediction]: 0.81\n"
     ]
    }
   ],
   "source": [
    "# Add polynomial and bias term with the feature vector using the sklearn PolynomialFeatures class\n",
    "poly_features = PolynomialFeatures(degree=poly_degree, include_bias=False)\n",
    "X_test_poly = poly_features.fit_transform(X_test)\n",
    "\n",
    "\n",
    "print(\"\\n----------------------------- Test Model Evaluation -----------------------------\")\n",
    "\n",
    "# Make prediction \n",
    "y_test_poly_predicted = lin_reg_ridge.predict(X_test_poly)\n",
    "\n",
    "\n",
    "ridge_test_mse = mean_squared_error(y_test, y_test_poly_predicted)\n",
    "\n",
    "print(\"\\nMean squared error: %.2f\" % ridge_test_mse)\n",
    "\n",
    "\n",
    "\n",
    "ridge_test_r2_score = r2_score(y_test, y_test_poly_predicted)\n",
    "print('Coefficient of determination r^2 variance score [1 is perfect prediction]: %.2f' \n",
    "      % ridge_test_r2_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a High-Degree Polynomial Data Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable that specifies the degree of the polynomial to be added to the feature vector\n",
    "poly_degree = optimal_degree\n",
    "\n",
    "\n",
    "# Add polynomial terms with the feature vector using the sklearn PolynomialFeatures class\n",
    "poly_features = PolynomialFeatures(degree=poly_degree, include_bias=False)\n",
    "X_train_poly = poly_features.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection Via Grid Search: Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n",
      "Best Score (negative mean squared error): -12.157443\n",
      "Optimal Hyperparameter Values:  {'alpha': 15.306122448979592}\n",
      "\n",
      "\n",
      "CPU times: user 240 ms, sys: 1.94 s, total: 2.18 s\n",
      "Wall time: 186 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# The param_grid tells Scikit-Learn to evaluate all combinations of the hyperparameter values\n",
    "\n",
    "#param_grid = {'alpha': np.linspace(10.0, 20.0, num=10)}\n",
    "param_grid = {'alpha': np.linspace(10.0, 20.0)}\n",
    "\n",
    "lasso = Lasso()\n",
    "\n",
    "lasso_cv = GridSearchCV(ridge, param_grid, scoring='neg_mean_squared_error', cv=10, verbose=1, n_jobs=-1)\n",
    "lasso_cv.fit(X_train_poly, y_train)\n",
    "\n",
    "params_optimal_lasso = lasso_cv.best_params_\n",
    "\n",
    "print(\"Best Score (negative mean squared error): %f\" % lasso_cv.best_score_)\n",
    "print(\"Optimal Hyperparameter Values: \", params_optimal_lasso)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select The Best Model for the Lasso Regressor\n",
    "\n",
    "Using the optimal hyperparameter values, create the best model.\n",
    "Then, fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal alpha:  15.306122448979592\n",
      "\n",
      "----------------------------- Model Evaluation -----------------------------\n",
      "\n",
      "Mean squared error: 6.59\n",
      "Coefficient of determination r^2 variance score [1 is perfect prediction]: 0.92\n"
     ]
    }
   ],
   "source": [
    "# Lasso Regression\n",
    "\n",
    "# Optimal model parameters\n",
    "lasso_alpha = lasso_cv.best_params_['alpha']\n",
    "print(\"Optimal alpha: \", lasso_alpha)\n",
    "\n",
    "\n",
    "# Create a Lasso linear regression object\n",
    "lin_reg_lasso = Ridge(alpha=lasso_alpha)\n",
    "\n",
    "# Train the model\n",
    "lin_reg_lasso.fit(X_train_poly, y_train)\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n----------------------------- Model Evaluation -----------------------------\")\n",
    "\n",
    "# Make prediction \n",
    "y_train_predicted_lasso = lin_reg_lasso.predict(X_train_poly)\n",
    "\n",
    "\n",
    "print(\"\\nMean squared error: %.2f\"\n",
    "      % mean_squared_error(y_train, y_train_predicted_lasso))\n",
    "\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print(\"Coefficient of determination r^2 variance score [1 is perfect prediction]: %.2f\" \n",
    "      % r2_score(y_train, y_train_predicted_lasso))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model Using Test Data: Lasso Regression\n",
    "\n",
    "We will use the optimal degree for the polynomial to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------- Test Model Evaluation -----------------------------\n",
      "\n",
      "Mean squared error: 13.27\n",
      "Coefficient of determination r^2 variance score [1 is perfect prediction]: 0.82\n"
     ]
    }
   ],
   "source": [
    "# Add polynomial and bias term with the feature vector using the sklearn PolynomialFeatures class\n",
    "poly_features = PolynomialFeatures(degree=poly_degree, include_bias=False)\n",
    "X_test_poly = poly_features.fit_transform(X_test)\n",
    "\n",
    "\n",
    "print(\"\\n----------------------------- Test Model Evaluation -----------------------------\")\n",
    "\n",
    "# Make prediction \n",
    "y_test_poly_predicted = lin_reg_lasso.predict(X_test_poly)\n",
    "\n",
    "lasso_test_mse = mean_squared_error(y_test, y_test_poly_predicted)\n",
    "\n",
    "print(\"\\nMean squared error: %.2f\" % lasso_test_mse)\n",
    "\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "lasso_test_r2_score = r2_score(y_test, y_test_poly_predicted)\n",
    "print('Coefficient of determination r^2 variance score [1 is perfect prediction]: %.2f' \n",
    "      % lasso_test_r2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Ridge Regression vs. Lasso Regression\n",
    "\n",
    "\n",
    "Lasso Regression uses an $l_1$ penalty, which tends to push the weights down to exactly zero. This leads to **<font color=red>sparse models</font>**, where all weights are zero except for the most important weights. This is a way to perform **feature selection** automatically, which is good if we suspect that only a few features actually matter. When we are not sure, we should prefer Ridge Regression.\n",
    "\n",
    "\n",
    "## Comparison of the Weight Values: Ridge Regression vs. Lasso Regression\n",
    "\n",
    "We will see that when the regularization coefficient (alpha) is large (e.g., $ \\geq 1.0$), Lasso regression tends to drive the weight values towards 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Ridge (alpha = 0.948)       Lasso (alpha = 15.306)\n",
      "   Test MSE = 14.150           Test MSE = 13.269\n",
      "   Test R2 Score = 0.807       Test R2 Score = 0.819\n",
      "________________________________________________________________\n",
      "\n",
      "      -0.137441                       -0.118603\n",
      "       0.034572                        0.041661\n",
      "      -0.069549                       -0.036095\n",
      "       0.087320                        0.088897\n",
      "      -0.790236                       -0.761097\n",
      "       3.618137                        3.434530\n",
      "      -0.866106                       -0.846633\n",
      "      -1.588963                       -1.403679\n",
      "       0.683862                        0.601534\n",
      "      -0.945291                       -0.901264\n",
      "      -0.815739                       -0.821862\n",
      "       0.565149                        0.515772\n",
      "      -3.144117                       -2.940098\n",
      "       0.023213                        0.036555\n",
      "       0.056275                        0.044253\n",
      "       0.068204                        0.072980\n",
      "       1.606316                        1.669695\n",
      "      -0.370681                       -0.476944\n",
      "       0.871498                        0.790648\n",
      "       0.214392                        0.164949\n",
      "       0.426364                        0.365950\n",
      "      -0.595716                       -0.572014\n",
      "       0.162870                        0.147403\n",
      "      -0.020922                        0.006484\n",
      "      -0.167371                       -0.166018\n",
      "       0.800041                        0.712194\n",
      "       0.253369                        0.237361\n",
      "      -0.127801                       -0.105956\n",
      "       0.273970                        0.231236\n",
      "       0.246986                        0.177588\n",
      "      -0.045526                       -0.023955\n",
      "       0.031523                       -0.001498\n",
      "      -0.279513                       -0.287695\n",
      "      -0.207190                       -0.283843\n",
      "       0.753907                        0.737992\n",
      "       0.268200                        0.215106\n",
      "       0.026585                       -0.062808\n",
      "      -0.570536                       -0.496904\n",
      "       0.775302                        0.732039\n",
      "       0.036188                        0.046212\n",
      "       0.570509                        0.595527\n",
      "       0.856330                        0.706430\n",
      "       0.590363                        0.553904\n",
      "       0.744600                        0.726403\n",
      "      -0.023186                        0.000289\n",
      "       0.314437                        0.300803\n",
      "      -0.568314                       -0.530388\n",
      "       0.104332                        0.127833\n",
      "      -0.725155                       -0.625986\n",
      "       0.289718                        0.294949\n",
      "      -1.191464                       -1.062453\n",
      "      -0.848021                       -0.776407\n",
      "       0.226767                        0.182748\n",
      "      -0.512317                       -0.485533\n",
      "       0.298281                        0.245548\n",
      "       0.673617                        0.591267\n",
      "      -0.187999                       -0.131688\n",
      "      -0.187740                       -0.120017\n",
      "      -0.428719                       -0.453635\n",
      "      -0.411879                       -0.445765\n",
      "      -0.902995                       -0.805749\n",
      "      -0.283496                       -0.250879\n",
      "       0.683397                        0.727756\n",
      "      -0.798373                       -0.663610\n",
      "       0.043550                        0.095735\n",
      "      -0.509776                       -0.478662\n",
      "      -0.186863                       -0.156985\n",
      "       0.616754                        0.523058\n",
      "       0.519412                        0.532640\n",
      "      -0.738755                       -0.673782\n",
      "       0.046539                        0.026185\n",
      "      -1.305192                       -1.164427\n",
      "      -0.911723                       -0.919223\n",
      "      -1.133709                       -1.035168\n",
      "      -0.510850                       -0.406839\n",
      "       0.049259                       -0.073211\n",
      "       0.041493                        0.100308\n",
      "       0.308593                        0.225767\n",
      "       0.855925                        0.853595\n",
      "       0.409143                        0.249601\n",
      "       0.111345                       -0.010783\n",
      "      -0.766600                       -0.718244\n",
      "      -1.116401                       -1.065326\n",
      "       1.084975                        0.969860\n",
      "       0.030273                       -0.028097\n",
      "      -0.011663                       -0.062921\n",
      "      -0.155718                       -0.147617\n",
      "      -0.310370                       -0.312017\n",
      "       0.665539                        0.675922\n",
      "      -0.699366                       -0.742703\n",
      "       0.718473                        0.715279\n",
      "       0.512326                        0.443789\n",
      "      -0.056719                       -0.015043\n",
      "      -1.437066                       -1.344249\n",
      "       0.322695                        0.216303\n",
      "       1.212964                        1.152493\n",
      "      -0.452249                       -0.437743\n",
      "      -1.197720                       -1.048501\n",
      "      -0.205869                       -0.159348\n",
      "       0.095868                        0.081416\n",
      "       0.201151                        0.183237\n",
      "      -0.320692                       -0.312762\n",
      "      -0.063374                       -0.146856\n",
      "       1.142126                        0.955828\n"
     ]
    }
   ],
   "source": [
    "print(\"%8s (alpha = %3.3f)  %10s (alpha = %3.3f)\" % (\"Ridge\",ridge_alpha, \"Lasso\", lasso_alpha))\n",
    "print(\"%2s Test MSE = %3.3f  %8s Test MSE = %3.3f\" % (\" \",ridge_test_mse, \" \", lasso_test_mse))\n",
    "print(\"%2s Test R2 Score = %3.3f  %4s Test R2 Score = %3.3f\" % (\" \",ridge_test_r2_score, \" \", lasso_test_r2_score))\n",
    "print(\"________________________________________________________________\\n\")\n",
    "for i in range(lin_reg_ridge.coef_.shape[0]):\n",
    "    print(\"%15f  %30f\" % (lin_reg_ridge.coef_[i], lin_reg_lasso.coef_[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Note: Regularized Polynomial Regression\n",
    "\n",
    "We observe that only by increasing model complexity (higher-degree polynomial) and regularizing its weights, we could improve performance on the test data for the given dataset."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
